<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>DeepTech Daily Dashboard</title>
  <style>
body { font-family: 'Inter', 'Segoe UI', system-ui, -apple-system, sans-serif; margin: 0; padding: 0; background: #0f172a; color: #e2e8f0; }
header { padding: 2.5rem 1.5rem; text-align: center; background: #1e293b; }
header h1 { margin: 0 0 0.5rem; font-size: 2.5rem; }
header p { margin: 0; color: #94a3b8; font-size: 1rem; }
main { max-width: 1100px; margin: 0 auto; padding: 2rem 1.5rem 4rem; }
section { background: rgba(15, 23, 42, 0.75); border: 1px solid rgba(148, 163, 184, 0.2); border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 12px 24px rgba(15, 23, 42, 0.4); }
section h2 { margin-top: 0; color: #f8fafc; font-size: 1.5rem; }
table { width: 100%; border-collapse: collapse; margin-top: 1rem; }
th, td { text-align: left; padding: 0.65rem 0.75rem; border-bottom: 1px solid rgba(148, 163, 184, 0.2); }
th { background: rgba(148, 163, 184, 0.1); color: #e2e8f0; font-weight: 600; }
tr:hover td { background: rgba(59, 130, 246, 0.08); }
a { color: #38bdf8; text-decoration: none; }
a:hover { text-decoration: underline; }
.warning { margin: 0.75rem 0; color: #fbbf24; }
.empty { margin: 1rem 0 0; color: #94a3b8; font-style: italic; }
.metadata { margin: 0.35rem 0 0; color: #94a3b8; font-size: 0.9rem; }
footer { text-align: center; padding: 2rem 1.5rem 3rem; color: #64748b; font-size: 0.9rem; }
footer ul { list-style: none; padding: 0; margin: 1rem 0 0; display: flex; flex-wrap: wrap; gap: 0.75rem; justify-content: center; }
footer li { background: rgba(148, 163, 184, 0.1); border-radius: 6px; padding: 0.4rem 0.75rem; }
</style>
</head>
<body>
  <header>
    <h1>DeepTech Daily Dashboard</h1>
    <p>A curated snapshot of GPUs, research, software, and security intel powered by the DeepTech Daily datasets.</p>
  </header>
  <main>
    <section>
  <h2>GPU Pricing Snapshot</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z • Source: <a href="https://vast.ai/api/v0/bundles/public" target="_blank" rel="noopener">https://vast.ai/api/v0/bundles/public</a>, <a href="https://api.runpod.io" target="_blank" rel="noopener">https://api.runpod.io</a>, <a href="https://modal.com/api" target="_blank" rel="noopener">https://modal.com/api</a> • Hash: <code>73cd0d24819c38ed4bb8d48de66e8dd1013b8b60870640a96bc6c90d3b6d6974</code></p>
  <p class="warning">Vast.ai: 404 Client Error: Not Found for url: https://console.vast.ai/api/v0/bundles/public/?limit=200&amp;skip=0</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>arXiv Digest</h2>
  <p class="metadata">Fetched at 2025-11-06T05:32:46Z • Source: <a href="https://export.arxiv.org/rss/cs.AI" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.AI</a>, <a href="https://export.arxiv.org/rss/cs.CL" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.CL</a>, <a href="https://export.arxiv.org/rss/cs.LG" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.LG</a> • Hash: <code>3028e57421e2c133d179126ca0f4c3970d1f58c0ea94583458f5f87e86150442</code></p>
  <table>
    <thead>
      <tr><th>Title</th><th>Summary</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://arxiv.org/abs/2511.02997" target="_blank" rel="noopener">Evaluating Control Protocols for Untrusted AI Agents</a></td><td>arXiv:2511.02997v1 Announce Type: new  Abstract: As AI systems become more capable and widely deployed as agents, ensuring their safe operation becomes critica…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03023" target="_blank" rel="noopener">PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework</a></td><td>arXiv:2511.03023v1 Announce Type: new  Abstract: Open data repositories hold potential for evidence-based decision-making, yet are inaccessible to non-experts…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03051" target="_blank" rel="noopener">No-Human in the Loop: Agentic Evaluation at Scale for Recommendation</a></td><td>arXiv:2511.03051v1 Announce Type: new  Abstract: Evaluating large language models (LLMs) as judges is increasingly critical for building scalable and trustwort…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03070" target="_blank" rel="noopener">Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge</a></td><td>arXiv:2511.03070v1 Announce Type: new  Abstract: Artificial intelligence (AI) systems hold great promise for advancing various scientific disciplines, and are…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03092" target="_blank" rel="noopener">SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators</a></td><td>arXiv:2511.03092v1 Announce Type: new  Abstract: The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+ context length support have resul…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03106" target="_blank" rel="noopener">Large language models require a new form of oversight: capability-based monitoring</a></td><td>arXiv:2511.03106v1 Announce Type: new  Abstract: The rapid adoption of large language models (LLMs) in healthcare has been accompanied by scrutiny of their ove…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03108" target="_blank" rel="noopener">miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward</a></td><td>arXiv:2511.03108v1 Announce Type: new  Abstract: We perform a thorough analysis of the formal and informal statements in the miniF2F benchmark from the perspec…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03137" target="_blank" rel="noopener">Using Multi-modal Large Language Model to Boost Fireworks Algorithm&#x27;s Ability in Settling Challenging Optimization Tasks</a></td><td>arXiv:2511.03137v1 Announce Type: new  Abstract: As optimization problems grow increasingly complex and diverse, advancements in optimization techniques and pa…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03138" target="_blank" rel="noopener">A Proprietary Model-Based Safety Response Framework for AI Agents</a></td><td>arXiv:2511.03138v1 Announce Type: new  Abstract: With the widespread application of Large Language Models (LLMs), their associated security issues have become…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03169" target="_blank" rel="noopener">Uncovering Bugs in Formal Explainers: A Case Study with PyXAI</a></td><td>arXiv:2511.03169v1 Announce Type: new  Abstract: Formal explainable artificial intelligence (XAI) offers unique theoretical guarantees of rigor when compared t…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03179" target="_blank" rel="noopener">Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework</a></td><td>arXiv:2511.03179v1 Announce Type: new  Abstract: The engineering design process often demands expertise from multiple domains, leading to complex collaboration…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03186" target="_blank" rel="noopener">Adobe Summit Concierge Evaluation with Human in the Loop</a></td><td>arXiv:2511.03186v1 Announce Type: new  Abstract: Generative AI assistants offer significant potential to enhance productivity, streamline information access, a…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03235" target="_blank" rel="noopener">From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers</a></td><td>arXiv:2511.03235v1 Announce Type: new  Abstract: Psychological constructs within individuals are widely believed to be interconnected. We investigated whether…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03471" target="_blank" rel="noopener">Towards Scalable Web Accessibility Audit with MLLMs as Copilots</a></td><td>arXiv:2511.03471v1 Announce Type: new  Abstract: Ensuring web accessibility is crucial for advancing social welfare, justice, and equality in digital spaces, y…</td><td>2025-11-06T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.03545" target="_blank" rel="noopener">Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)</a></td><td>arXiv:2511.03545v1 Announce Type: new  Abstract: This paper presents a comprehensive theoretical investigation into the parameterized complexity of explanation…</td><td>2025-11-06T05:00:00Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Models</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z • Source: <a href="https://huggingface.co/api/models" target="_blank" rel="noopener">https://huggingface.co/api/models</a> • Hash: <code>edb3d86947c5f8d876d9c4481cb4419a0d2e7876af7b8f691870930c02d571fc</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Model</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/Falconsai/nsfw_image_detection" target="_blank" rel="noopener">Falconsai/nsfw_image_detection</a></td><td>122866637</td><td>847</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" target="_blank" rel="noopener">sentence-transformers/all-MiniLM-L6-v2</a></td><td>118061338</td><td>4004</td></tr>
      <tr><td><a href="https://huggingface.co/dima806/fairface_age_image_detection" target="_blank" rel="noopener">dima806/fairface_age_image_detection</a></td><td>81641974</td><td>44</td></tr>
      <tr><td><a href="https://huggingface.co/google/electra-base-discriminator" target="_blank" rel="noopener">google/electra-base-discriminator</a></td><td>58549625</td><td>66</td></tr>
      <tr><td><a href="https://huggingface.co/google-bert/bert-base-uncased" target="_blank" rel="noopener">google-bert/bert-base-uncased</a></td><td>53275807</td><td>2441</td></tr>
      <tr><td><a href="https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k" target="_blank" rel="noopener">timm/mobilenetv3_small_100.lamb_in1k</a></td><td>43762365</td><td>39</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-large" target="_blank" rel="noopener">FacebookAI/roberta-large</a></td><td>20426777</td><td>250</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" target="_blank" rel="noopener">sentence-transformers/all-mpnet-base-v2</a></td><td>17830892</td><td>1170</td></tr>
      <tr><td><a href="https://huggingface.co/openai/clip-vit-base-patch32" target="_blank" rel="noopener">openai/clip-vit-base-patch32</a></td><td>17638896</td><td>782</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/segmentation-3.0" target="_blank" rel="noopener">pyannote/segmentation-3.0</a></td><td>17234148</td><td>626</td></tr>
      <tr><td><a href="https://huggingface.co/tech4humans/yolov8s-signature-detector" target="_blank" rel="noopener">tech4humans/yolov8s-signature-detector</a></td><td>16874538</td><td>48</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM" target="_blank" rel="noopener">pyannote/wespeaker-voxceleb-resnet34-LM</a></td><td>14933122</td><td>80</td></tr>
      <tr><td><a href="https://huggingface.co/Bingsu/adetailer" target="_blank" rel="noopener">Bingsu/adetailer</a></td><td>14489181</td><td>620</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-base" target="_blank" rel="noopener">FacebookAI/roberta-base</a></td><td>14321545</td><td>529</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/speaker-diarization-3.1" target="_blank" rel="noopener">pyannote/speaker-diarization-3.1</a></td><td>14186095</td><td>1228</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>GitHub Trending Repositories</h2>
  <p class="metadata">Fetched at 2025-11-06T05:32:46Z • Source: <a href="https://api.github.com/search/repositories" target="_blank" rel="noopener">https://api.github.com/search/repositories</a> • Hash: <code>e7763a57db8d7dcad54816a9cb1deed174ea7cfd04b63df6b06dfa2ca3acedf0</code></p>
  <table>
    <thead>
      <tr><th>Repository</th><th>Stars</th><th>Description</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://github.com/bonejohnson8/BONERBOTS-OPEN-SOURCE-PUBLIC-v1.0" target="_blank" rel="noopener">bonejohnson8/BONERBOTS-OPEN-SOURCE-PUBLIC-v1.0</a></td><td>31</td><td>BonerBots Day 1 release with livetrading LLM bots on AsterDEX</td></tr>
      <tr><td><a href="https://github.com/chongzixuan-ai/mcp-server-website" target="_blank" rel="noopener">chongzixuan-ai/mcp-server-website</a></td><td>28</td><td>Quickly screenshots webpages and converts to an LLM friendly size</td></tr>
      <tr><td><a href="https://github.com/lukema95/roma-01" target="_blank" rel="noopener">lukema95/roma-01</a></td><td>23</td><td>A competitive AI-powered cryptocurrency futures trading platform featuring a NOF1-inspired interface (nof1.ai) for showcasing multiple LLM models side-by-side,…</td></tr>
      <tr><td><a href="https://github.com/qingshungLI/Super-nof1.ai" target="_blank" rel="noopener">qingshungLI/Super-nof1.ai</a></td><td>19</td><td>Inspired by Alpha Arena and open-nof1.ai,we want to explore the new trading way of ai-trading.we will improve the LLMs and use machine learning to analyse the…</td></tr>
      <tr><td><a href="https://github.com/AmirhosseinHonardoust/RAG-vs-Fine-Tuning" target="_blank" rel="noopener">AmirhosseinHonardoust/RAG-vs-Fine-Tuning</a></td><td>13</td><td>A comprehensive, professional guide explaining the differences, strengths, and best practices of Retrieval-Augmented Generation (RAG) and Fine-Tuning for LLMs,…</td></tr>
      <tr><td><a href="https://github.com/Lianues/LLM-NeedleInAHaystack" target="_blank" rel="noopener">Lianues/LLM-NeedleInAHaystack</a></td><td>11</td><td>Needle in a Haystack benchmark for evaluating LLM recall and attention mechanisms with edit distance scoring.</td></tr>
      <tr><td><a href="https://github.com/xxynet/KiraAI" target="_blank" rel="noopener">xxynet/KiraAI</a></td><td>11</td><td>KiraAI, a modular, multi-platform AI virtual being that connects Large Language Models (LLMs), Text-to-Speech (TTS), and various chat adapters (QQ, Telegram, B…</td></tr>
      <tr><td><a href="https://github.com/kingkongshot/Figma-Bridge" target="_blank" rel="noopener">kingkongshot/Figma-Bridge</a></td><td>8</td><td>Bridge from Figma designs to LLM-friendly HTML/CSS code</td></tr>
      <tr><td><a href="https://github.com/elijah0528/tacc" target="_blank" rel="noopener">elijah0528/tacc</a></td><td>7</td><td>Tokenization-Aware Compression Codec to efficiently send LLM outputs over low-bandwidth networks</td></tr>
      <tr><td><a href="https://github.com/Programming-from-A-to-Z/Ollama-Context-RAG" target="_blank" rel="noopener">Programming-from-A-to-Z/Ollama-Context-RAG</a></td><td>6</td><td>Example Demonstrating Retrieval Augmented Generation with transformers.js embeddings and Ollama LLMs.</td></tr>
      <tr><td><a href="https://github.com/diegoeis/product-spec-kit" target="_blank" rel="noopener">diegoeis/product-spec-kit</a></td><td>6</td><td>Leverage AI to create, refine, and maintain your product specifications. Made to be used in LLMs and IDEs.</td></tr>
      <tr><td><a href="https://github.com/0xPolygon/apk-mcp-llm-wallet" target="_blank" rel="noopener">0xPolygon/apk-mcp-llm-wallet</a></td><td>5</td><td>LLM Wallet MCP server, allowing LLMs to have their own crypto wallet</td></tr>
      <tr><td><a href="https://github.com/ArnavSharma938/SYNTEXIS" target="_blank" rel="noopener">ArnavSharma938/SYNTEXIS</a></td><td>5</td><td>Benchmarking Autoformalization and Subsequent Execution of Mathematical Reasoning in Large Language Models through Chain-of-Thought</td></tr>
      <tr><td><a href="https://github.com/Nikkei/fast-mia" target="_blank" rel="noopener">Nikkei/fast-mia</a></td><td>5</td><td>A framework designed to streamline the evaluation of Membership Inference Attacks (MIA) against Large Language Models (LLMs). By leveraging vLLM, it enables fa…</td></tr>
      <tr><td><a href="https://github.com/izreal1990-collab/MillennialAi" target="_blank" rel="noopener">izreal1990-collab/MillennialAi</a></td><td>5</td><td>Revolutionary Layer Injection Architecture for TRM-LLM Integration - Seamless integration of Tiny Recursion Models into Large Language Models using PyTorch for…</td></tr>
      <tr><td><a href="https://github.com/martin-kukla/tritex" target="_blank" rel="noopener">martin-kukla/tritex</a></td><td>5</td><td>Pre-Training LLMs in Triton from the first principle. It replicates GPT2 (1.6B) with 57.5% MFU on A100 SXM.</td></tr>
      <tr><td><a href="https://github.com/Telsho/Extrai" target="_blank" rel="noopener">Telsho/Extrai</a></td><td>4</td><td>Structured data extraction with LLM majority vote</td></tr>
      <tr><td><a href="https://github.com/bluearchio/aws-misconfig-db" target="_blank" rel="noopener">bluearchio/aws-misconfig-db</a></td><td>4</td><td>llm-formatted aws misconfiguration library</td></tr>
      <tr><td><a href="https://github.com/r-wenger/LLMFileDescribe" target="_blank" rel="noopener">r-wenger/LLMFileDescribe</a></td><td>4</td><td>QGIS plugin for AI-powered geospatial data description using local LLMs (Ollama).</td></tr>
      <tr><td><a href="https://github.com/sam1am/sekrit" target="_blank" rel="noopener">sam1am/sekrit</a></td><td>4</td><td>Implementation of &quot;LLMs can hide text in other text of the same length&quot; by Antonio Norelli &amp; Michael Bronstein.</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Papers with Code</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z • Source: <a href="https://paperswithcode.com/api/v1/papers/" target="_blank" rel="noopener">https://paperswithcode.com/api/v1/papers/</a> • Hash: <code>d4a343f7408e936b9b783882d60713e7711a2e2104b924d1a9726c2b1660e60c</code></p>
  <p class="warning">Expecting value: line 1 column 1 (char 0)</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>Hacker News Highlights</h2>
  <p class="metadata">Fetched at 2025-11-06T05:32:46Z • Source: <a href="https://hacker-news.firebaseio.com/" target="_blank" rel="noopener">https://hacker-news.firebaseio.com/</a> • Hash: <code>25cdf355cdb1b97a958d643e59aea5270460e805823e7eb9c4a40b900dd11e5d</code></p>
  <table>
    <thead>
      <tr><th>Story</th><th>Score</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://int10h.org/blog/2025/11/lost-ibm-at-model-bios-analysis/" target="_blank" rel="noopener">A Lost IBM PC/at Model? Analyzing a Newfound Old Bios</a></td><td>72</td><td>2025-11-05T20:40:39Z</td></tr>
      <tr><td><a href="https://9to5mac.com/2025/11/05/google-gemini-1-billion-deal-apple-siri/" target="_blank" rel="noopener">Apple nears $1B Google deal for custom Gemini model to power Siri</a></td><td>54</td><td>2025-11-05T19:43:22Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.02824" target="_blank" rel="noopener">Kosmos: An AI Scientist for Autonomous Discovery</a></td><td>51</td><td>2025-11-05T14:43:26Z</td></tr>
      <tr><td><a href="https://investinglive.com/stock-market-update/icymi-openai-asks-us-for-loan-guarantees-to-fund-1-trillion-ai-expansion-20251105/" target="_blank" rel="noopener">OpenAI asks U.S. for loan guarantees to fund $1T AI expansion</a></td><td>42</td><td>2025-11-06T01:32:08Z</td></tr>
      <tr><td><a href="https://www.reuters.com/world/asia-pacific/global-markets-ai-selloff-pix-2025-11-05/" target="_blank" rel="noopener">Don&#x27;t panic yet, investors say as high-flying AI stocks tumble</a></td><td>41</td><td>2025-11-05T14:35:33Z</td></tr>
      <tr><td><a href="https://techcrunch.com/2025/11/05/tinder-to-use-ai-to-get-to-know-users-tap-into-their-camera-roll-photos/" target="_blank" rel="noopener">Tinder is testing an AI feature that learns about you from your Camera Roll</a></td><td>19</td><td>2025-11-05T19:33:10Z</td></tr>
      <tr><td><a href="https://www.wsj.com/video/openai-wants-federal-backstop-for-new-investments/4F6C864C-7332-448B-A9B4-66C321E60FE7" target="_blank" rel="noopener">OpenAI Wants Federal Backstop for New Investments [video]</a></td><td>16</td><td>2025-11-05T22:30:15Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Latest CVEs</h2>
  <p class="metadata">Fetched at 2025-11-06T05:32:46Z • Source: <a href="https://cve.circl.lu/api/last" target="_blank" rel="noopener">https://cve.circl.lu/api/last</a> • Hash: <code>0a8772b1ac41e471b757ef46ee6e8c2455fb5e31163a0ddbb6d31de61a591bd2</code></p>
  <table>
    <thead>
      <tr><th>CVE</th><th>CVSS</th><th>Summary</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-54236" target="_blank" rel="noopener">CVE-2025-54236</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-gj84-8vfx-q3vm" target="_blank" rel="noopener">GHSA-gj84-8vfx-q3vm</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-6w73-x38p-26g5" target="_blank" rel="noopener">GHSA-6w73-x38p-26g5</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-64171" target="_blank" rel="noopener">CVE-2025-64171</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-q7xf-93c3-w2p7" target="_blank" rel="noopener">GHSA-q7xf-93c3-w2p7</a></td><td>0.0</td><td></td></tr>
      <tr><td>N/A</td><td>0.0</td><td></td></tr>
      <tr><td>N/A</td><td>0.0</td><td></td></tr>
      <tr><td>N/A</td><td>0.0</td><td></td></tr>
      <tr><td>N/A</td><td>0.0</td><td></td></tr>
      <tr><td>N/A</td><td>0.0</td><td></td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Datasets</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z • Source: <a href="https://huggingface.co/api/datasets" target="_blank" rel="noopener">https://huggingface.co/api/datasets</a> • Hash: <code>4b4cc33871c4b3cd497c500155aa79f37885aa24df2d895e1d18c0c80ab6ae9c</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Dataset</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/datasets/nebius/SWE-rebench" target="_blank" rel="noopener">nebius/SWE-rebench</a></td><td>3717252</td><td>35</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/SWE-Gym/SWE-Gym" target="_blank" rel="noopener">SWE-Gym/SWE-Gym</a></td><td>2041687</td><td>20</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/huggingface/documentation-images" target="_blank" rel="noopener">huggingface/documentation-images</a></td><td>2014781</td><td>86</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/chcorbi/helvipad" target="_blank" rel="noopener">chcorbi/helvipad</a></td><td>1478443</td><td>10</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/AquaV/genshin-voices-separated" target="_blank" rel="noopener">AquaV/genshin-voices-separated</a></td><td>1461805</td><td>8</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/banned-historical-archives/banned-historical-archives" target="_blank" rel="noopener">banned-historical-archives/banned-historical-archives</a></td><td>1411450</td><td>5</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim" target="_blank" rel="noopener">nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim</a></td><td>1339503</td><td>155</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/princeton-nlp/SWE-bench_Verified" target="_blank" rel="noopener">princeton-nlp/SWE-bench_Verified</a></td><td>1282494</td><td>218</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/lavita/medical-qa-shared-task-v1-toy" target="_blank" rel="noopener">lavita/medical-qa-shared-task-v1-toy</a></td><td>878541</td><td>21</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/Salesforce/wikitext" target="_blank" rel="noopener">Salesforce/wikitext</a></td><td>867174</td><td>505</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/language_table_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/language_table_lerobot</a></td><td>786287</td><td>0</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/droid_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/droid_lerobot</a></td><td>737114</td><td>6</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/hf-doc-build/doc-build" target="_blank" rel="noopener">hf-doc-build/doc-build</a></td><td>671848</td><td>12</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/applied-ai-018/pretraining_v1-omega_books" target="_blank" rel="noopener">applied-ai-018/pretraining_v1-omega_books</a></td><td>614296</td><td>2</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu" target="_blank" rel="noopener">HuggingFaceFW/fineweb-edu</a></td><td>597646</td><td>775</td></tr>
    </tbody>
  </table>
</section>
  </main>
  <footer><p>Datasets updated as part of the DeepTech Daily automation run.</p><p>Last refreshed at 2025-11-06T05:32:46Z.</p><ul><li><a href="../deeptech-daily/data/gpu_prices.json">gpu_prices.json</a></li><li><a href="../deeptech-daily/data/arxiv.yaml">arxiv.yaml</a></li><li><a href="../deeptech-daily/data/hf_trending.yaml">hf_trending.yaml</a></li><li><a href="../deeptech-daily/data/github_trending.yaml">github_trending.yaml</a></li><li><a href="../deeptech-daily/data/pwc_llm.yaml">pwc_llm.yaml</a></li><li><a href="../deeptech-daily/data/hn_ai.yaml">hn_ai.yaml</a></li><li><a href="../deeptech-daily/data/cves.yaml">cves.yaml</a></li><li><a href="../deeptech-daily/data/hf_datasets.yaml">hf_datasets.yaml</a></li></ul></footer>
</body>
</html>
