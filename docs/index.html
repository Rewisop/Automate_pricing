<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>DeepTech Daily Dashboard</title>
  <style>
body { font-family: 'Inter', 'Segoe UI', system-ui, -apple-system, sans-serif; margin: 0; padding: 0; background: #0f172a; color: #e2e8f0; }
header { padding: 2.5rem 1.5rem; text-align: center; background: #1e293b; }
header h1 { margin: 0 0 0.5rem; font-size: 2.5rem; }
header p { margin: 0; color: #94a3b8; font-size: 1rem; }
main { max-width: 1100px; margin: 0 auto; padding: 2rem 1.5rem 4rem; }
section { background: rgba(15, 23, 42, 0.75); border: 1px solid rgba(148, 163, 184, 0.2); border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 12px 24px rgba(15, 23, 42, 0.4); }
section h2 { margin-top: 0; color: #f8fafc; font-size: 1.5rem; }
table { width: 100%; border-collapse: collapse; margin-top: 1rem; }
th, td { text-align: left; padding: 0.65rem 0.75rem; border-bottom: 1px solid rgba(148, 163, 184, 0.2); }
th { background: rgba(148, 163, 184, 0.1); color: #e2e8f0; font-weight: 600; }
tr:hover td { background: rgba(59, 130, 246, 0.08); }
a { color: #38bdf8; text-decoration: none; }
a:hover { text-decoration: underline; }
.warning { margin: 0.75rem 0; color: #fbbf24; }
.empty { margin: 1rem 0 0; color: #94a3b8; font-style: italic; }
.metadata { margin: 0.35rem 0 0; color: #94a3b8; font-size: 0.9rem; }
footer { text-align: center; padding: 2rem 1.5rem 3rem; color: #64748b; font-size: 0.9rem; }
footer ul { list-style: none; padding: 0; margin: 1rem 0 0; display: flex; flex-wrap: wrap; gap: 0.75rem; justify-content: center; }
footer li { background: rgba(148, 163, 184, 0.1); border-radius: 6px; padding: 0.4rem 0.75rem; }
</style>
</head>
<body>
  <header>
    <h1>DeepTech Daily Dashboard</h1>
    <p>A curated snapshot of GPUs, research, software, and security intel powered by the DeepTech Daily datasets.</p>
  </header>
  <main>
    <section>
  <h2>GPU Pricing Snapshot</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z ‚Ä¢ Source: <a href="https://vast.ai/api/v0/bundles/public" target="_blank" rel="noopener">https://vast.ai/api/v0/bundles/public</a>, <a href="https://api.runpod.io" target="_blank" rel="noopener">https://api.runpod.io</a>, <a href="https://modal.com/api" target="_blank" rel="noopener">https://modal.com/api</a> ‚Ä¢ Hash: <code>73cd0d24819c38ed4bb8d48de66e8dd1013b8b60870640a96bc6c90d3b6d6974</code></p>
  <p class="warning">Vast.ai: 404 Client Error: Not Found for url: https://console.vast.ai/api/v0/bundles/public/?limit=200&amp;skip=0</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>arXiv Digest</h2>
  <p class="metadata">Fetched at 2025-10-30T05:31:34Z ‚Ä¢ Source: <a href="https://export.arxiv.org/rss/cs.AI" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.AI</a>, <a href="https://export.arxiv.org/rss/cs.CL" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.CL</a>, <a href="https://export.arxiv.org/rss/cs.LG" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.LG</a> ‚Ä¢ Hash: <code>13d382b02377d0a68a1b00393f4fe0caf3067370cad7b3b2dd9d3f10776d7570</code></p>
  <table>
    <thead>
      <tr><th>Title</th><th>Summary</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://arxiv.org/abs/2510.24832" target="_blank" rel="noopener">Scheduling Your LLM Reinforcement Learning with Reasoning Trees</a></td><td>arXiv:2510.24832v1 Announce Type: new  Abstract: Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large Language Models (LLMs) can be co‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25005" target="_blank" rel="noopener">Cyclic Counterfactuals under Shift-Scale Interventions</a></td><td>arXiv:2510.25005v1 Announce Type: new  Abstract: Most counterfactual inference frameworks traditionally assume acyclic structural causal models (SCMs), i.e. di‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25007" target="_blank" rel="noopener">Taming the Real-world Complexities in CPT E/M Coding with Large Language Models</a></td><td>arXiv:2510.25007v1 Announce Type: new  Abstract: Evaluation and Management (E/M) coding, under the Current Procedural Terminology (CPT) taxonomy, documents med‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25014" target="_blank" rel="noopener">Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading</a></td><td>arXiv:2510.25014v1 Announce Type: new  Abstract: Large Language Models (LLMs) enable dynamic game interactions but fail to follow essential procedural flows in‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25065" target="_blank" rel="noopener">Reasoning-Aware GRPO using Process Mining</a></td><td>arXiv:2510.25065v1 Announce Type: new  Abstract: Reinforcement learning (RL)-based post-training has been crucial for enabling multi-step reasoning in large re‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25091" target="_blank" rel="noopener">H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and Style-Structured Mixture of Experts</a></td><td>arXiv:2510.25091v1 Announce Type: new  Abstract: Stock movement prediction remains fundamentally challenging due to complex temporal dependencies, heterogeneou‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25101" target="_blank" rel="noopener">KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA</a></td><td>arXiv:2510.25101v1 Announce Type: new  Abstract: Knowledge Base Question Answering (KBQA) aims to answer natural-language questions over a structured Knowledge‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25179" target="_blank" rel="noopener">Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models</a></td><td>arXiv:2510.25179v1 Announce Type: new  Abstract: Agentic methods have emerged as a powerful and autonomous paradigm that enhances reasoning, collaboration, and‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25205" target="_blank" rel="noopener">Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision</a></td><td>arXiv:2510.25205v1 Announce Type: new  Abstract: Autonomous driving is an emerging technology that is expected to bring significant social, economic, and envir‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25206" target="_blank" rel="noopener">RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models</a></td><td>arXiv:2510.25206v1 Announce Type: new  Abstract: Reinforcement learning (RL) can refine the reasoning abilities of large language models (LLMs), but critically‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25223" target="_blank" rel="noopener">FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data</a></td><td>arXiv:2510.25223v1 Announce Type: new  Abstract: Event log data, recording fine-grained user actions and system events, represent one of the most valuable asse‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25232" target="_blank" rel="noopener">From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity</a></td><td>arXiv:2510.25232v1 Announce Type: new  Abstract: Psychiatric comorbidity is clinically significant yet challenging due to the complexity of multiple co-occurri‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25320" target="_blank" rel="noopener">GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning</a></td><td>arXiv:2510.25320v1 Announce Type: new  Abstract: Autonomous agents powered by large language models (LLMs) have shown impressive capabilities in tool manipulat‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25388" target="_blank" rel="noopener">Grouping Nodes With Known Value Differences: A Lossless UCT-based Abstraction Algorithm</a></td><td>arXiv:2510.25388v1 Announce Type: new  Abstract: A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency, which can be improved by grouping‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.25445" target="_blank" rel="noopener">Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions</a></td><td>arXiv:2510.25445v1 Announce Type: new  Abstract: Agentic AI represents a transformative shift in artificial intelligence, but its rapid advancement has led to‚Ä¶</td><td>2025-10-30T04:00:00Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Models</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z ‚Ä¢ Source: <a href="https://huggingface.co/api/models" target="_blank" rel="noopener">https://huggingface.co/api/models</a> ‚Ä¢ Hash: <code>edb3d86947c5f8d876d9c4481cb4419a0d2e7876af7b8f691870930c02d571fc</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Model</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/Falconsai/nsfw_image_detection" target="_blank" rel="noopener">Falconsai/nsfw_image_detection</a></td><td>122866637</td><td>847</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" target="_blank" rel="noopener">sentence-transformers/all-MiniLM-L6-v2</a></td><td>118061338</td><td>4004</td></tr>
      <tr><td><a href="https://huggingface.co/dima806/fairface_age_image_detection" target="_blank" rel="noopener">dima806/fairface_age_image_detection</a></td><td>81641974</td><td>44</td></tr>
      <tr><td><a href="https://huggingface.co/google/electra-base-discriminator" target="_blank" rel="noopener">google/electra-base-discriminator</a></td><td>58549625</td><td>66</td></tr>
      <tr><td><a href="https://huggingface.co/google-bert/bert-base-uncased" target="_blank" rel="noopener">google-bert/bert-base-uncased</a></td><td>53275807</td><td>2441</td></tr>
      <tr><td><a href="https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k" target="_blank" rel="noopener">timm/mobilenetv3_small_100.lamb_in1k</a></td><td>43762365</td><td>39</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-large" target="_blank" rel="noopener">FacebookAI/roberta-large</a></td><td>20426777</td><td>250</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" target="_blank" rel="noopener">sentence-transformers/all-mpnet-base-v2</a></td><td>17830892</td><td>1170</td></tr>
      <tr><td><a href="https://huggingface.co/openai/clip-vit-base-patch32" target="_blank" rel="noopener">openai/clip-vit-base-patch32</a></td><td>17638896</td><td>782</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/segmentation-3.0" target="_blank" rel="noopener">pyannote/segmentation-3.0</a></td><td>17234148</td><td>626</td></tr>
      <tr><td><a href="https://huggingface.co/tech4humans/yolov8s-signature-detector" target="_blank" rel="noopener">tech4humans/yolov8s-signature-detector</a></td><td>16874538</td><td>48</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM" target="_blank" rel="noopener">pyannote/wespeaker-voxceleb-resnet34-LM</a></td><td>14933122</td><td>80</td></tr>
      <tr><td><a href="https://huggingface.co/Bingsu/adetailer" target="_blank" rel="noopener">Bingsu/adetailer</a></td><td>14489181</td><td>620</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-base" target="_blank" rel="noopener">FacebookAI/roberta-base</a></td><td>14321545</td><td>529</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/speaker-diarization-3.1" target="_blank" rel="noopener">pyannote/speaker-diarization-3.1</a></td><td>14186095</td><td>1228</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>GitHub Trending Repositories</h2>
  <p class="metadata">Fetched at 2025-10-30T05:31:34Z ‚Ä¢ Source: <a href="https://api.github.com/search/repositories" target="_blank" rel="noopener">https://api.github.com/search/repositories</a> ‚Ä¢ Hash: <code>b88f73fbcf94159b6f465191d948444ea72023f6ea85c9e6023dddfca5b1ae0e</code></p>
  <table>
    <thead>
      <tr><th>Repository</th><th>Stars</th><th>Description</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://github.com/barodeur/llm_rescuer" target="_blank" rel="noopener">barodeur/llm_rescuer</a></td><td>133</td><td>Fix the Billion Dollar Mistake with an LLM</td></tr>
      <tr><td><a href="https://github.com/FoundationAgents/ReCode" target="_blank" rel="noopener">FoundationAgents/ReCode</a></td><td>52</td><td>Next paradigm for LLM Agent. Unify plan and action through recursive code generation for adaptive, human-like decision-making.</td></tr>
      <tr><td><a href="https://github.com/xaviviro/python-toon" target="_blank" rel="noopener">xaviviro/python-toon</a></td><td>42</td><td>üêç TOON for Python (Token-Oriented Object Notation) - Reduce LLM token costs by 30-60% with structured data.</td></tr>
      <tr><td><a href="https://github.com/alpkeskin/gotoon" target="_blank" rel="noopener">alpkeskin/gotoon</a></td><td>22</td><td>Token-Oriented Object Notation for Go ‚Äì JSON for LLMs at half the token cost</td></tr>
      <tr><td><a href="https://github.com/samogod/samoscout" target="_blank" rel="noopener">samogod/samoscout</a></td><td>22</td><td>one-for-all llm powered, passive &amp; active subdomain enumeration tool</td></tr>
      <tr><td><a href="https://github.com/TencentYoutuResearch/APTBench" target="_blank" rel="noopener">TencentYoutuResearch/APTBench</a></td><td>21</td><td>Code for &quot;APTBench: Benchmarking Agentic Potential of Base LLMs During Pre-Training&quot;</td></tr>
      <tr><td><a href="https://github.com/jolehuit/clother" target="_blank" rel="noopener">jolehuit/clother</a></td><td>21</td><td>Configure and launch multiple Claude Code‚Äìcompatible LLM providers from one CLI, switching profiles instantly with simple clother-* commands.</td></tr>
      <tr><td><a href="https://github.com/jsjfai/AgentDNS" target="_blank" rel="noopener">jsjfai/AgentDNS</a></td><td>21</td><td>AgentDNS is the core component of Agent network that facilitates agent registration and discovery, enabling large language models (LLMs) to browse the internet‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/jsjfai/AgentConnector" target="_blank" rel="noopener">jsjfai/AgentConnector</a></td><td>20</td><td>AgentConnector is a feature-rich open-source Agent Network Client built upon DeepChat, supporting Agent network, multiple cloud and local large language models‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/zfkarl/UniFER" target="_blank" rel="noopener">zfkarl/UniFER</a></td><td>13</td><td>Official repository for the paper ‚ÄúRethinking Facial Expression Recognition in the Era of Multimodal Large Language Models‚Äù</td></tr>
      <tr><td><a href="https://github.com/BandarLabs/open-skills" target="_blank" rel="noopener">BandarLabs/open-skills</a></td><td>12</td><td>OpenSkills: Run Claude Skills Locally using any LLM</td></tr>
      <tr><td><a href="https://github.com/HelgeSverre/toon-php" target="_blank" rel="noopener">HelgeSverre/toon-php</a></td><td>12</td><td>Token-Oriented Object Notation - A compact data format for reducing token consumption when sending structured data to LLMs (PHP implementation)</td></tr>
      <tr><td><a href="https://github.com/gwh22/UniVoice" target="_blank" rel="noopener">gwh22/UniVoice</a></td><td>12</td><td>UniVoice: Unifying Autoregressive ASR and Flow-Matching based TTS with Large Language Models</td></tr>
      <tr><td><a href="https://github.com/hkirat/ai-trading-agent" target="_blank" rel="noopener">hkirat/ai-trading-agent</a></td><td>12</td><td>Trade using LLMs</td></tr>
      <tr><td><a href="https://github.com/leslieo2/LieGraph" target="_blank" rel="noopener">leslieo2/LieGraph</a></td><td>11</td><td>LieGraph - AI Agent-Driven &quot;Who Is Spy&quot; Game. Multi-agent social deduction game built with LangGraph where autonomous AI agents use LLM reasoning to find the s‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/zenoaihq/tson" target="_blank" rel="noopener">zenoaihq/tson</a></td><td>10</td><td>Token-efficient Structured Object Notation for LLMs</td></tr>
      <tr><td><a href="https://github.com/Emo-gml/PsyLLM" target="_blank" rel="noopener">Emo-gml/PsyLLM</a></td><td>9</td><td>Beyond Empathy: Integrating Diagnostic and Therapeutic Reasoning with Large Language Models for Mental Health Counseling</td></tr>
      <tr><td><a href="https://github.com/TeleAI-UAGI/Awesome-Agent-Memory" target="_blank" rel="noopener">TeleAI-UAGI/Awesome-Agent-Memory</a></td><td>9</td><td>Curated papers, systems, and benchmarks on memory for LLMs/MLLMs‚Äîlong-term context, retrieval, and reasoning.</td></tr>
      <tr><td><a href="https://github.com/lemon07r/VellumForge2" target="_blank" rel="noopener">lemon07r/VellumForge2</a></td><td>9</td><td>VellumForge2 is a Golang CLI for generating high-quality Direct Preference Optimization datasets via a hierarchical prompt pipeline with optional LLM-as-a-Judg‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/pavolloffay/opentelemetry-mcp-server" target="_blank" rel="noopener">pavolloffay/opentelemetry-mcp-server</a></td><td>8</td><td>Model Context Protocol (MCP) Server for OpenTelemetry to enable your LLM be an OTEL expert.</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Papers with Code</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z ‚Ä¢ Source: <a href="https://paperswithcode.com/api/v1/papers/" target="_blank" rel="noopener">https://paperswithcode.com/api/v1/papers/</a> ‚Ä¢ Hash: <code>d4a343f7408e936b9b783882d60713e7711a2e2104b924d1a9726c2b1660e60c</code></p>
  <p class="warning">Expecting value: line 1 column 1 (char 0)</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>Hacker News Highlights</h2>
  <p class="metadata">Fetched at 2025-10-30T05:31:34Z ‚Ä¢ Source: <a href="https://hacker-news.firebaseio.com/" target="_blank" rel="noopener">https://hacker-news.firebaseio.com/</a> ‚Ä¢ Hash: <code>023c4f2febe7c12be0214a0fd061e406e0d06a323191e97b97236a2c6fb9e6fa</code></p>
  <table>
    <thead>
      <tr><th>Story</th><th>Score</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://cursor.com/blog/composer" target="_blank" rel="noopener">Composer: Building a fast frontier model with RL</a></td><td>185</td><td>2025-10-29T16:04:33Z</td></tr>
      <tr><td><a href="https://www.wsj.com/tech/ai/openais-promise-to-stay-in-california-helped-clear-the-path-for-its-ipo-3af1c31c" target="_blank" rel="noopener">OpenAI‚Äôs promise to stay in California helped clear the path for its IPO</a></td><td>172</td><td>2025-10-29T17:44:34Z</td></tr>
      <tr><td><a href="https://techcrunch.com/2025/10/29/grammarly-rebrands-to-superhuman-launches-a-new-ai-assistant/" target="_blank" rel="noopener">Grammarly rebrands to &#x27;Superhuman,&#x27; launches a new AI assistant</a></td><td>125</td><td>2025-10-29T13:12:23Z</td></tr>
      <tr><td><a href="https://www.nytimes.com/2025/10/29/technology/characterai-underage-users.html" target="_blank" rel="noopener">Character.ai to bar children under 18 from using its chatbots</a></td><td>80</td><td>2025-10-29T13:52:31Z</td></tr>
      <tr><td><a href="https://www.theguardian.com/books/2025/oct/22/detection-firm-finds-82-of-herbal-remedy-books-on-amazon-likely-written-by-ai" target="_blank" rel="noopener">Detection firm finds 82% of herbal remedy books on Amazon &#x27;likely written&#x27; by AI</a></td><td>28</td><td>2025-10-29T21:47:58Z</td></tr>
      <tr><td><a href="https://www.tomshardware.com/tech-industry/data-centers-turn-to-ex-airliner-engines-as-ai-power-crunch-bites" target="_blank" rel="noopener">Data centers turn to commercial aircraft jet engines as AI power crunch bites</a></td><td>3</td><td>2025-10-30T02:47:31Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Latest CVEs</h2>
  <p class="metadata">Fetched at 2025-10-30T05:31:34Z ‚Ä¢ Source: <a href="https://cve.circl.lu/api/last" target="_blank" rel="noopener">https://cve.circl.lu/api/last</a> ‚Ä¢ Hash: <code>dd4d9705aa025ff0d9adf1f000034c31ec1080b705706b79374f4c25c15ca7a8</code></p>
  <table>
    <thead>
      <tr><th>CVE</th><th>CVSS</th><th>Summary</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-7h23-57pg-3hwc" target="_blank" rel="noopener">GHSA-7h23-57pg-3hwc</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-41821" target="_blank" rel="noopener">MAL-2025-41821</a></td><td>0.0</td><td>Malicious code in esm-package (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2022-50238" target="_blank" rel="noopener">CVE-2022-50238</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-59033" target="_blank" rel="noopener">CVE-2025-59033</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-h935-vxwx-xh2m" target="_blank" rel="noopener">GHSA-h935-vxwx-xh2m</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-9900" target="_blank" rel="noopener">CVE-2025-9900</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-qc8j-wvjf-7jfj" target="_blank" rel="noopener">GHSA-qc8j-wvjf-7jfj</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-48605" target="_blank" rel="noopener">MAL-2025-48605</a></td><td>0.0</td><td>Malicious code in near-abi-client-js (npm)</td></tr>
      <tr><td>N/A</td><td>0.0</td><td></td></tr>
      <tr><td>N/A</td><td>0.0</td><td></td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Datasets</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z ‚Ä¢ Source: <a href="https://huggingface.co/api/datasets" target="_blank" rel="noopener">https://huggingface.co/api/datasets</a> ‚Ä¢ Hash: <code>4b4cc33871c4b3cd497c500155aa79f37885aa24df2d895e1d18c0c80ab6ae9c</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Dataset</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/datasets/nebius/SWE-rebench" target="_blank" rel="noopener">nebius/SWE-rebench</a></td><td>3717252</td><td>35</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/SWE-Gym/SWE-Gym" target="_blank" rel="noopener">SWE-Gym/SWE-Gym</a></td><td>2041687</td><td>20</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/huggingface/documentation-images" target="_blank" rel="noopener">huggingface/documentation-images</a></td><td>2014781</td><td>86</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/chcorbi/helvipad" target="_blank" rel="noopener">chcorbi/helvipad</a></td><td>1478443</td><td>10</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/AquaV/genshin-voices-separated" target="_blank" rel="noopener">AquaV/genshin-voices-separated</a></td><td>1461805</td><td>8</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/banned-historical-archives/banned-historical-archives" target="_blank" rel="noopener">banned-historical-archives/banned-historical-archives</a></td><td>1411450</td><td>5</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim" target="_blank" rel="noopener">nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim</a></td><td>1339503</td><td>155</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/princeton-nlp/SWE-bench_Verified" target="_blank" rel="noopener">princeton-nlp/SWE-bench_Verified</a></td><td>1282494</td><td>218</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/lavita/medical-qa-shared-task-v1-toy" target="_blank" rel="noopener">lavita/medical-qa-shared-task-v1-toy</a></td><td>878541</td><td>21</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/Salesforce/wikitext" target="_blank" rel="noopener">Salesforce/wikitext</a></td><td>867174</td><td>505</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/language_table_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/language_table_lerobot</a></td><td>786287</td><td>0</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/droid_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/droid_lerobot</a></td><td>737114</td><td>6</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/hf-doc-build/doc-build" target="_blank" rel="noopener">hf-doc-build/doc-build</a></td><td>671848</td><td>12</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/applied-ai-018/pretraining_v1-omega_books" target="_blank" rel="noopener">applied-ai-018/pretraining_v1-omega_books</a></td><td>614296</td><td>2</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu" target="_blank" rel="noopener">HuggingFaceFW/fineweb-edu</a></td><td>597646</td><td>775</td></tr>
    </tbody>
  </table>
</section>
  </main>
  <footer><p>Datasets updated as part of the DeepTech Daily automation run.</p><p>Last refreshed at 2025-10-30T05:31:34Z.</p><ul><li><a href="../deeptech-daily/data/gpu_prices.json">gpu_prices.json</a></li><li><a href="../deeptech-daily/data/arxiv.yaml">arxiv.yaml</a></li><li><a href="../deeptech-daily/data/hf_trending.yaml">hf_trending.yaml</a></li><li><a href="../deeptech-daily/data/github_trending.yaml">github_trending.yaml</a></li><li><a href="../deeptech-daily/data/pwc_llm.yaml">pwc_llm.yaml</a></li><li><a href="../deeptech-daily/data/hn_ai.yaml">hn_ai.yaml</a></li><li><a href="../deeptech-daily/data/cves.yaml">cves.yaml</a></li><li><a href="../deeptech-daily/data/hf_datasets.yaml">hf_datasets.yaml</a></li></ul></footer>
</body>
</html>
