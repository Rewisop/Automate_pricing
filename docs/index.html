<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>DeepTech Daily Dashboard</title>
  <style>
body { font-family: 'Inter', 'Segoe UI', system-ui, -apple-system, sans-serif; margin: 0; padding: 0; background: #0f172a; color: #e2e8f0; }
header { padding: 2.5rem 1.5rem; text-align: center; background: #1e293b; }
header h1 { margin: 0 0 0.5rem; font-size: 2.5rem; }
header p { margin: 0; color: #94a3b8; font-size: 1rem; }
main { max-width: 1100px; margin: 0 auto; padding: 2rem 1.5rem 4rem; }
section { background: rgba(15, 23, 42, 0.75); border: 1px solid rgba(148, 163, 184, 0.2); border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 12px 24px rgba(15, 23, 42, 0.4); }
section h2 { margin-top: 0; color: #f8fafc; font-size: 1.5rem; }
table { width: 100%; border-collapse: collapse; margin-top: 1rem; }
th, td { text-align: left; padding: 0.65rem 0.75rem; border-bottom: 1px solid rgba(148, 163, 184, 0.2); }
th { background: rgba(148, 163, 184, 0.1); color: #e2e8f0; font-weight: 600; }
tr:hover td { background: rgba(59, 130, 246, 0.08); }
a { color: #38bdf8; text-decoration: none; }
a:hover { text-decoration: underline; }
.warning { margin: 0.75rem 0; color: #fbbf24; }
.empty { margin: 1rem 0 0; color: #94a3b8; font-style: italic; }
.metadata { margin: 0.35rem 0 0; color: #94a3b8; font-size: 0.9rem; }
footer { text-align: center; padding: 2rem 1.5rem 3rem; color: #64748b; font-size: 0.9rem; }
footer ul { list-style: none; padding: 0; margin: 1rem 0 0; display: flex; flex-wrap: wrap; gap: 0.75rem; justify-content: center; }
footer li { background: rgba(148, 163, 184, 0.1); border-radius: 6px; padding: 0.4rem 0.75rem; }
</style>
</head>
<body>
  <header>
    <h1>DeepTech Daily Dashboard</h1>
    <p>A curated snapshot of GPUs, research, software, and security intel powered by the DeepTech Daily datasets.</p>
  </header>
  <main>
    <section>
  <h2>GPU Pricing Snapshot</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z • Source: <a href="https://vast.ai/api/v0/bundles/public" target="_blank" rel="noopener">https://vast.ai/api/v0/bundles/public</a>, <a href="https://api.runpod.io" target="_blank" rel="noopener">https://api.runpod.io</a>, <a href="https://modal.com/api" target="_blank" rel="noopener">https://modal.com/api</a> • Hash: <code>73cd0d24819c38ed4bb8d48de66e8dd1013b8b60870640a96bc6c90d3b6d6974</code></p>
  <p class="warning">Vast.ai: 404 Client Error: Not Found for url: https://console.vast.ai/api/v0/bundles/public/?limit=200&amp;skip=0</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>arXiv Digest</h2>
  <p class="metadata">Fetched at 2025-10-22T05:32:14Z • Source: <a href="https://export.arxiv.org/rss/cs.AI" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.AI</a>, <a href="https://export.arxiv.org/rss/cs.CL" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.CL</a>, <a href="https://export.arxiv.org/rss/cs.LG" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.LG</a> • Hash: <code>eaae4410bd9224d985fdf9c8ca673c31f46059284bdd8451ad54af9830791b7a</code></p>
  <table>
    <thead>
      <tr><th>Title</th><th>Summary</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://arxiv.org/abs/2510.17902" target="_blank" rel="noopener">Activation Manifold Projection: Liberating Task-Specific Behaviors from LLM Architectures</a></td><td>arXiv:2510.17902v1 Announce Type: new  Abstract: The proliferation of Large Language Model (LLM) architectures presents a fundamental challenge: valuable, task…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.17940" target="_blank" rel="noopener">Beyond More Context: Retrieval Diversity Boosts Multi-Turn Intent Understanding</a></td><td>arXiv:2510.17940v1 Announce Type: new  Abstract: Multi turn intent understanding is central to task oriented chatbots, yet real deployments face tight token bu…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.17995" target="_blank" rel="noopener">FABRIC: Framework for Agent-Based Realistic Intelligence Creation</a></td><td>arXiv:2510.17995v1 Announce Type: new  Abstract: Large language models (LLMs) are increasingly deployed as agents, expected to decompose goals, invoke tools, a…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.18032" target="_blank" rel="noopener">OPTAGENT: Optimizing Multi-Agent LLM Interactions Through Verbal Reinforcement Learning for Enhanced Reasoning</a></td><td>arXiv:2510.18032v1 Announce Type: new  Abstract: Large Language Models (LLMs) have shown remarkable reasoning capabilities in mathematical and scientific tasks…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.18040" target="_blank" rel="noopener">Subject-Event Ontology Without Global Time: Foundations and Execution Semantics</a></td><td>arXiv:2510.18040v1 Announce Type: new  Abstract: A formalization of a subject-event ontology is proposed for modeling complex dynamic systems without reliance…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.18043" target="_blank" rel="noopener">CompactPrompt: A Unified Pipeline for Prompt Data Compression in LLM Workflows</a></td><td>arXiv:2510.18043v1 Announce Type: new  Abstract: Large Language Models (LLMs) deliver powerful reasoning and generation capabilities but incur substantial run-…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.18087" target="_blank" rel="noopener">Planned Diffusion</a></td><td>arXiv:2510.18087v1 Announce Type: new  Abstract: A central challenge in large language model inference is the trade-off between generation speed and output qua…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.18095" target="_blank" rel="noopener">SMaRT: Select, Mix, and ReinvenT - A Strategy Fusion Framework for LLM-Driven Reasoning and Planning</a></td><td>arXiv:2510.18095v1 Announce Type: new  Abstract: Large Language Models (LLMs) have redefined complex task automation with exceptional generalization capabiliti…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.18134" target="_blank" rel="noopener">Measuring Reasoning in LLMs: a New Dialectical Angle</a></td><td>arXiv:2510.18134v1 Announce Type: new  Abstract: What does it truly mean for a language model to &quot;reason&quot;? Most current evaluations and benchmarks reward model…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.18143" target="_blank" rel="noopener">Learning from Generalization Patterns: An Evaluation-Driven Approach to Enhanced Data Augmentation for Fine-Tuning Small Language Models</a></td><td>arXiv:2510.18143v1 Announce Type: new  Abstract: Small Language Models (SLMs) offer compelling advantages in deployment cost and latency, but their accuracy of…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.18154" target="_blank" rel="noopener">Annotating the Chain-of-Thought: A Behavior-Labeled Dataset for AI Safety</a></td><td>arXiv:2510.18154v1 Announce Type: new  Abstract: Recent work has highlighted the importance of monitoring chain-of-thought reasoning for AI safety; however, cu…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.18155" target="_blank" rel="noopener">LLM-Based Multi-Agent System for Simulating and Analyzing Marketing and Consumer Behavior</a></td><td>arXiv:2510.18155v1 Announce Type: new  Abstract: Simulating consumer decision-making is vital for designing and evaluating marketing strategies before costly r…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.18165" target="_blank" rel="noopener">Saber: An Efficient Sampling with Adaptive Acceleration and Backtracking Enhanced Remasking for Diffusion Language Model</a></td><td>arXiv:2510.18165v1 Announce Type: new  Abstract: Diffusion language models (DLMs) are emerging as a powerful and promising alternative to the dominant autoregr…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.18170" target="_blank" rel="noopener">AgentChangeBench: A Multi-Dimensional Evaluation Framework for Goal-Shift Robustness in Conversational AI</a></td><td>arXiv:2510.18170v1 Announce Type: new  Abstract: Goal changes are a defining feature of real world multi-turn interactions, yet current agent benchmarks primar…</td><td>2025-10-22T04:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.18176" target="_blank" rel="noopener">Local Coherence or Global Validity? Investigating RLVR Traces in Math Domains</a></td><td>arXiv:2510.18176v1 Announce Type: new  Abstract: Reinforcement Learning with Verifiable Rewards (RLVR)-based post-training of Large Language Models (LLMs) has…</td><td>2025-10-22T04:00:00Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Models</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z • Source: <a href="https://huggingface.co/api/models" target="_blank" rel="noopener">https://huggingface.co/api/models</a> • Hash: <code>edb3d86947c5f8d876d9c4481cb4419a0d2e7876af7b8f691870930c02d571fc</code></p>
  <p class="warning">401 Client Error: Unauthorized for url: https://huggingface.co/api/models?sort=downloads&amp;direction=-1&amp;limit=15 (Request ID: Root=1-68f86c66-6be61b805de274e51f3ed2ff;1e93704d-9720-4cd2-b560-c04ac6c9fe49) Invalid credentials in Authorization header</p>
  <table>
    <thead>
      <tr><th>Model</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/Falconsai/nsfw_image_detection" target="_blank" rel="noopener">Falconsai/nsfw_image_detection</a></td><td>122866637</td><td>847</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" target="_blank" rel="noopener">sentence-transformers/all-MiniLM-L6-v2</a></td><td>118061338</td><td>4004</td></tr>
      <tr><td><a href="https://huggingface.co/dima806/fairface_age_image_detection" target="_blank" rel="noopener">dima806/fairface_age_image_detection</a></td><td>81641974</td><td>44</td></tr>
      <tr><td><a href="https://huggingface.co/google/electra-base-discriminator" target="_blank" rel="noopener">google/electra-base-discriminator</a></td><td>58549625</td><td>66</td></tr>
      <tr><td><a href="https://huggingface.co/google-bert/bert-base-uncased" target="_blank" rel="noopener">google-bert/bert-base-uncased</a></td><td>53275807</td><td>2441</td></tr>
      <tr><td><a href="https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k" target="_blank" rel="noopener">timm/mobilenetv3_small_100.lamb_in1k</a></td><td>43762365</td><td>39</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-large" target="_blank" rel="noopener">FacebookAI/roberta-large</a></td><td>20426777</td><td>250</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" target="_blank" rel="noopener">sentence-transformers/all-mpnet-base-v2</a></td><td>17830892</td><td>1170</td></tr>
      <tr><td><a href="https://huggingface.co/openai/clip-vit-base-patch32" target="_blank" rel="noopener">openai/clip-vit-base-patch32</a></td><td>17638896</td><td>782</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/segmentation-3.0" target="_blank" rel="noopener">pyannote/segmentation-3.0</a></td><td>17234148</td><td>626</td></tr>
      <tr><td><a href="https://huggingface.co/tech4humans/yolov8s-signature-detector" target="_blank" rel="noopener">tech4humans/yolov8s-signature-detector</a></td><td>16874538</td><td>48</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM" target="_blank" rel="noopener">pyannote/wespeaker-voxceleb-resnet34-LM</a></td><td>14933122</td><td>80</td></tr>
      <tr><td><a href="https://huggingface.co/Bingsu/adetailer" target="_blank" rel="noopener">Bingsu/adetailer</a></td><td>14489181</td><td>620</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-base" target="_blank" rel="noopener">FacebookAI/roberta-base</a></td><td>14321545</td><td>529</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/speaker-diarization-3.1" target="_blank" rel="noopener">pyannote/speaker-diarization-3.1</a></td><td>14186095</td><td>1228</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>GitHub Trending Repositories</h2>
  <p class="metadata">Fetched at 2025-10-22T05:32:14Z • Source: <a href="https://api.github.com/search/repositories" target="_blank" rel="noopener">https://api.github.com/search/repositories</a> • Hash: <code>a491c9682f540d5cf4c57d4981cbc3e69bb446fa906d5c0e10f508ad1530565f</code></p>
  <table>
    <thead>
      <tr><th>Repository</th><th>Stars</th><th>Description</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://github.com/ellydee/acceptance-bench" target="_blank" rel="noopener">ellydee/acceptance-bench</a></td><td>58</td><td>A robust LLM evaluation framework measuring acceptance vs refusal across difficulty levels. Features multi-prompt variation testing, temperature sweeping, and…</td></tr>
      <tr><td><a href="https://github.com/llm-brain-rot/llm-brain-rot" target="_blank" rel="noopener">llm-brain-rot/llm-brain-rot</a></td><td>51</td><td>LLM Can Get &quot;Brain Rot&quot;</td></tr>
      <tr><td><a href="https://github.com/AI4Science-WestlakeU/BuildArena" target="_blank" rel="noopener">AI4Science-WestlakeU/BuildArena</a></td><td>40</td><td>BuildArena, where LLM agents design, build, and test rockets, cars, and bridges in a physics simulator given a goal-directed sentence.</td></tr>
      <tr><td><a href="https://github.com/ysz/recursive-llm" target="_blank" rel="noopener">ysz/recursive-llm</a></td><td>28</td><td>Recursive Language Models for unbounded context processing. Process 100k+ tokens with any LLM by storing context as variables instead of prompts.</td></tr>
      <tr><td><a href="https://github.com/skye-harris/hass_local_openai_llm" target="_blank" rel="noopener">skye-harris/hass_local_openai_llm</a></td><td>20</td><td>Home Assistant LLM integration for local OpenAI-compatible services (llamacpp, vllm, etc)</td></tr>
      <tr><td><a href="https://github.com/nilesh2797/lattice" target="_blank" rel="noopener">nilesh2797/lattice</a></td><td>13</td><td>LATTICE turns retrieval into an LLM-driven navigation problem over a semantic scaffold</td></tr>
      <tr><td><a href="https://github.com/VisionXLab/ProCLIP" target="_blank" rel="noopener">VisionXLab/ProCLIP</a></td><td>11</td><td>Official PyTorch implementation of ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder</td></tr>
      <tr><td><a href="https://github.com/tranngocphu/custom_langchain_chat_model" target="_blank" rel="noopener">tranngocphu/custom_langchain_chat_model</a></td><td>11</td><td>LangChain-Compatible Wrapper for Any Private LLM APIs</td></tr>
      <tr><td><a href="https://github.com/Tomsawyerhu/Awesome-Personalized-Alignment" target="_blank" rel="noopener">Tomsawyerhu/Awesome-Personalized-Alignment</a></td><td>10</td><td>A Survey on Large Language Models for Personalized Alignment</td></tr>
      <tr><td><a href="https://github.com/kristaller486/RuQualBench" target="_blank" rel="noopener">kristaller486/RuQualBench</a></td><td>10</td><td>RuQualBench: A benchmark for evaluating the quality of the Russian language in LLM responses</td></tr>
      <tr><td><a href="https://github.com/LLM4SOC-Topic/RulePilot" target="_blank" rel="noopener">LLM4SOC-Topic/RulePilot</a></td><td>8</td><td>RulePilot: the first language- and theory-agonistic SIEM Rule generation engine via LLM agents</td></tr>
      <tr><td><a href="https://github.com/TimmyOVO/freshrss-filter" target="_blank" rel="noopener">TimmyOVO/freshrss-filter</a></td><td>8</td><td>AI-Powered RSS Content Filter - Automatically remove ads, sponsored content, and low-quality articles from your FreshRSS feeds using LLM intelligence. Set it &amp;…</td></tr>
      <tr><td><a href="https://github.com/fkesheh/skill-mcp" target="_blank" rel="noopener">fkesheh/skill-mcp</a></td><td>8</td><td>LLM-managed skills platform using MCP - create, edit, and execute skills programmatically in Claude, Cursor, and any MCP-compatible client without manual file…</td></tr>
      <tr><td><a href="https://github.com/Blaspsoft/forerunner" target="_blank" rel="noopener">Blaspsoft/forerunner</a></td><td>7</td><td>🏗️✨ Define structured output schemas for LLMs using Laravel&#x27;s familiar migration syntax</td></tr>
      <tr><td><a href="https://github.com/flybirdxx/ComfyUI-RexOmni" target="_blank" rel="noopener">flybirdxx/ComfyUI-RexOmni</a></td><td>7</td><td>Rex-Omni is a 3B-parameter Multimodal Large Language Model (MLLM) that redefines object detection and a wide range of other visual perception tasks as a simple…</td></tr>
      <tr><td><a href="https://github.com/HankYe/KVCOMM" target="_blank" rel="noopener">HankYe/KVCOMM</a></td><td>6</td><td>[NeurIPS&#x27;25] KVCOMM: Online Cross-context KV-cache Communication for Efficient LLM-based Multi-agent Systems</td></tr>
      <tr><td><a href="https://github.com/NuyoahCh/LLMForge" target="_blank" rel="noopener">NuyoahCh/LLMForge</a></td><td>6</td><td>一份面向开发者的开源教程，用于系统学习如何构建、部署和优化基于大语言模型（LLM）的智能应用。</td></tr>
      <tr><td><a href="https://github.com/Rubin-Wei/MLPMemory" target="_blank" rel="noopener">Rubin-Wei/MLPMemory</a></td><td>6</td><td>The official implementation of the paper &quot;MLP Memory: A Retriever-Pretrained Memory for Large Language Models&quot;.</td></tr>
      <tr><td><a href="https://github.com/gfyddha/UDS" target="_blank" rel="noopener">gfyddha/UDS</a></td><td>6</td><td>Official implementation of our paper: &quot;Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning.&quot;</td></tr>
      <tr><td><a href="https://github.com/ocicl/LispIndex" target="_blank" rel="noopener">ocicl/LispIndex</a></td><td>6</td><td>A structured index of Common Lisp systems, packages, and code examples — organized for semantic search and LLM-assisted discovery.</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Papers with Code</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z • Source: <a href="https://paperswithcode.com/api/v1/papers/" target="_blank" rel="noopener">https://paperswithcode.com/api/v1/papers/</a> • Hash: <code>d4a343f7408e936b9b783882d60713e7711a2e2104b924d1a9726c2b1660e60c</code></p>
  <p class="warning">Expecting value: line 1 column 1 (char 0)</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>Hacker News Highlights</h2>
  <p class="metadata">Fetched at 2025-10-22T05:32:14Z • Source: <a href="https://hacker-news.firebaseio.com/" target="_blank" rel="noopener">https://hacker-news.firebaseio.com/</a> • Hash: <code>31907ee32e3497695300a07d7744f48ff99542e78b0e85a6e6943fe44c2dad60</code></p>
  <table>
    <thead>
      <tr><th>Story</th><th>Score</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://tawandamunongo.dev/posts/2025/10/ai-work-more" target="_blank" rel="noopener">AI is making us work more</a></td><td>201</td><td>2025-10-21T15:19:51Z</td></tr>
      <tr><td><a href="https://calnewport.com/is-sora-the-beginning-of-the-end-for-openai/" target="_blank" rel="noopener">Is Sora the beginning of the end for OpenAI?</a></td><td>160</td><td>2025-10-21T16:01:17Z</td></tr>
      <tr><td><a href="https://www.bloomberg.com/news/articles/2025-10-21/openai-set-to-challenge-google-with-new-chatgpt-atlas-browser" target="_blank" rel="noopener">OpenAI Set to Challenge Google with New ChatGPT Atlas Browser</a></td><td>33</td><td>2025-10-21T17:03:34Z</td></tr>
      <tr><td><a href="https://nymag.com/intelligencer/article/wikipedia-contributors-are-worried-about-ai-scraping.html" target="_blank" rel="noopener">Wikipedia Seems Pretty Worried About AI</a></td><td>29</td><td>2025-10-21T08:54:33Z</td></tr>
      <tr><td><a href="https://www.theregister.com/2025/10/21/ai_eats_leisure_time/" target="_blank" rel="noopener">AI eats leisure time, makes employees work more, study finds</a></td><td>14</td><td>2025-10-21T20:46:36Z</td></tr>
      <tr><td><a href="https://gizmodo.com/dhs-asks-openai-to-unmask-user-behind-chatgpt-prompts-possibly-the-first-such-case-2000674472" target="_blank" rel="noopener">DHS Asks OpenAI to Unmask User Behind ChatGPT Prompts, Possibly First Such Case</a></td><td>12</td><td>2025-10-22T00:07:06Z</td></tr>
      <tr><td><a href="https://www.bloomberg.com/news/articles/2025-10-21/anthropic-google-in-talks-on-cloud-deal-worth-tens-of-billions" target="_blank" rel="noopener">Anthropic, Google in Talks on Cloud Deal Worth Billions</a></td><td>10</td><td>2025-10-21T21:46:54Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2510.05186" target="_blank" rel="noopener">OptPipe: Memory- and Scheduling-Optimized Pipeline Parallelism for LLM Training</a></td><td>6</td><td>2025-10-21T22:18:07Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Latest CVEs</h2>
  <p class="metadata">Fetched at 2025-10-22T05:32:14Z • Source: <a href="https://cve.circl.lu/api/last" target="_blank" rel="noopener">https://cve.circl.lu/api/last</a> • Hash: <code>1daa902cb19a0e982918dfc592231be560c5586be21c58840f963da25b3a4d43</code></p>
  <table>
    <thead>
      <tr><th>CVE</th><th>CVSS</th><th>Summary</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-6493-28fj-f93w" target="_blank" rel="noopener">GHSA-6493-28fj-f93w</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-f7j6-xrjp-vffg" target="_blank" rel="noopener">GHSA-f7j6-xrjp-vffg</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-w62w-9g5v-w3p4" target="_blank" rel="noopener">GHSA-w62w-9g5v-w3p4</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-w64p-pvrc-c5w3" target="_blank" rel="noopener">GHSA-w64p-pvrc-c5w3</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-p8wc-6g47-vh8j" target="_blank" rel="noopener">GHSA-p8wc-6g47-vh8j</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-wjjh-xg7v-8wf9" target="_blank" rel="noopener">GHSA-wjjh-xg7v-8wf9</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-fg66-4vpm-36cx" target="_blank" rel="noopener">GHSA-fg66-4vpm-36cx</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-x629-5xff-w7qg" target="_blank" rel="noopener">GHSA-x629-5xff-w7qg</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-3qq4-w757-rjqm" target="_blank" rel="noopener">GHSA-3qq4-w757-rjqm</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-hgq8-fc97-42ff" target="_blank" rel="noopener">GHSA-hgq8-fc97-42ff</a></td><td>0.0</td><td></td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Datasets</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z • Source: <a href="https://huggingface.co/api/datasets" target="_blank" rel="noopener">https://huggingface.co/api/datasets</a> • Hash: <code>4b4cc33871c4b3cd497c500155aa79f37885aa24df2d895e1d18c0c80ab6ae9c</code></p>
  <p class="warning">401 Client Error: Unauthorized for url: https://huggingface.co/api/datasets?sort=downloads&amp;direction=-1&amp;limit=15 (Request ID: Root=1-68f86c76-48f36e4b2286ab632a5120d5;e091805c-806b-4ffb-ae23-1084b30e06ac) Invalid credentials in Authorization header</p>
  <table>
    <thead>
      <tr><th>Dataset</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/datasets/nebius/SWE-rebench" target="_blank" rel="noopener">nebius/SWE-rebench</a></td><td>3717252</td><td>35</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/SWE-Gym/SWE-Gym" target="_blank" rel="noopener">SWE-Gym/SWE-Gym</a></td><td>2041687</td><td>20</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/huggingface/documentation-images" target="_blank" rel="noopener">huggingface/documentation-images</a></td><td>2014781</td><td>86</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/chcorbi/helvipad" target="_blank" rel="noopener">chcorbi/helvipad</a></td><td>1478443</td><td>10</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/AquaV/genshin-voices-separated" target="_blank" rel="noopener">AquaV/genshin-voices-separated</a></td><td>1461805</td><td>8</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/banned-historical-archives/banned-historical-archives" target="_blank" rel="noopener">banned-historical-archives/banned-historical-archives</a></td><td>1411450</td><td>5</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim" target="_blank" rel="noopener">nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim</a></td><td>1339503</td><td>155</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/princeton-nlp/SWE-bench_Verified" target="_blank" rel="noopener">princeton-nlp/SWE-bench_Verified</a></td><td>1282494</td><td>218</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/lavita/medical-qa-shared-task-v1-toy" target="_blank" rel="noopener">lavita/medical-qa-shared-task-v1-toy</a></td><td>878541</td><td>21</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/Salesforce/wikitext" target="_blank" rel="noopener">Salesforce/wikitext</a></td><td>867174</td><td>505</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/language_table_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/language_table_lerobot</a></td><td>786287</td><td>0</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/droid_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/droid_lerobot</a></td><td>737114</td><td>6</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/hf-doc-build/doc-build" target="_blank" rel="noopener">hf-doc-build/doc-build</a></td><td>671848</td><td>12</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/applied-ai-018/pretraining_v1-omega_books" target="_blank" rel="noopener">applied-ai-018/pretraining_v1-omega_books</a></td><td>614296</td><td>2</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu" target="_blank" rel="noopener">HuggingFaceFW/fineweb-edu</a></td><td>597646</td><td>775</td></tr>
    </tbody>
  </table>
</section>
  </main>
  <footer><p>Datasets updated as part of the DeepTech Daily automation run.</p><p>Last refreshed at 2025-10-22T05:32:14Z.</p><ul><li><a href="../deeptech-daily/data/gpu_prices.json">gpu_prices.json</a></li><li><a href="../deeptech-daily/data/arxiv.yaml">arxiv.yaml</a></li><li><a href="../deeptech-daily/data/hf_trending.yaml">hf_trending.yaml</a></li><li><a href="../deeptech-daily/data/github_trending.yaml">github_trending.yaml</a></li><li><a href="../deeptech-daily/data/pwc_llm.yaml">pwc_llm.yaml</a></li><li><a href="../deeptech-daily/data/hn_ai.yaml">hn_ai.yaml</a></li><li><a href="../deeptech-daily/data/cves.yaml">cves.yaml</a></li><li><a href="../deeptech-daily/data/hf_datasets.yaml">hf_datasets.yaml</a></li></ul></footer>
</body>
</html>
