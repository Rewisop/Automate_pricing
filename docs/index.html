<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>DeepTech Daily Dashboard</title>
  <style>
body { font-family: 'Inter', 'Segoe UI', system-ui, -apple-system, sans-serif; margin: 0; padding: 0; background: #0f172a; color: #e2e8f0; }
header { padding: 2.5rem 1.5rem; text-align: center; background: #1e293b; }
header h1 { margin: 0 0 0.5rem; font-size: 2.5rem; }
header p { margin: 0; color: #94a3b8; font-size: 1rem; }
main { max-width: 1100px; margin: 0 auto; padding: 2rem 1.5rem 4rem; }
section { background: rgba(15, 23, 42, 0.75); border: 1px solid rgba(148, 163, 184, 0.2); border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 12px 24px rgba(15, 23, 42, 0.4); }
section h2 { margin-top: 0; color: #f8fafc; font-size: 1.5rem; }
table { width: 100%; border-collapse: collapse; margin-top: 1rem; }
th, td { text-align: left; padding: 0.65rem 0.75rem; border-bottom: 1px solid rgba(148, 163, 184, 0.2); }
th { background: rgba(148, 163, 184, 0.1); color: #e2e8f0; font-weight: 600; }
tr:hover td { background: rgba(59, 130, 246, 0.08); }
a { color: #38bdf8; text-decoration: none; }
a:hover { text-decoration: underline; }
.warning { margin: 0.75rem 0; color: #fbbf24; }
.empty { margin: 1rem 0 0; color: #94a3b8; font-style: italic; }
.metadata { margin: 0.35rem 0 0; color: #94a3b8; font-size: 0.9rem; }
footer { text-align: center; padding: 2rem 1.5rem 3rem; color: #64748b; font-size: 0.9rem; }
footer ul { list-style: none; padding: 0; margin: 1rem 0 0; display: flex; flex-wrap: wrap; gap: 0.75rem; justify-content: center; }
footer li { background: rgba(148, 163, 184, 0.1); border-radius: 6px; padding: 0.4rem 0.75rem; }
</style>
</head>
<body>
  <header>
    <h1>DeepTech Daily Dashboard</h1>
    <p>A curated snapshot of GPUs, research, software, and security intel powered by the DeepTech Daily datasets.</p>
  </header>
  <main>
    <section>
  <h2>GPU Pricing Snapshot</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z ‚Ä¢ Source: <a href="https://vast.ai/api/v0/bundles/public" target="_blank" rel="noopener">https://vast.ai/api/v0/bundles/public</a>, <a href="https://api.runpod.io" target="_blank" rel="noopener">https://api.runpod.io</a>, <a href="https://modal.com/api" target="_blank" rel="noopener">https://modal.com/api</a> ‚Ä¢ Hash: <code>73cd0d24819c38ed4bb8d48de66e8dd1013b8b60870640a96bc6c90d3b6d6974</code></p>
  <p class="warning">Vast.ai: 404 Client Error: Not Found for url: https://console.vast.ai/api/v0/bundles/public/?limit=200&amp;skip=0</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>arXiv Digest</h2>
  <p class="metadata">Fetched at 2025-12-08T05:36:11Z ‚Ä¢ Source: <a href="https://export.arxiv.org/rss/cs.AI" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.AI</a>, <a href="https://export.arxiv.org/rss/cs.CL" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.CL</a>, <a href="https://export.arxiv.org/rss/cs.LG" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.LG</a> ‚Ä¢ Hash: <code>775689d77de3d266741d6455b79aff1d4cb23ae8ee359802ad1c09f89c1caa18</code></p>
  <table>
    <thead>
      <tr><th>Title</th><th>Summary</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://arxiv.org/abs/2512.05122" target="_blank" rel="noopener">Documenting SME Processes with Conversational AI: From Tacit Knowledge to BPMN</a></td><td>arXiv:2512.05122v1 Announce Type: new  Abstract: Small and medium-sized enterprises (SMEs) still depend heavily on tacit, experience-based know-how that rarely‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05156" target="_blank" rel="noopener">Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations</a></td><td>arXiv:2512.05156v1 Announce Type: new  Abstract: Evaluating faithfulness of Large Language Models (LLMs) to a given task is a complex challenge. We propose two‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05167" target="_blank" rel="noopener">Bridging Traditional Machine Learning and Large Language Models: A Two-Part Course Design for Modern AI Education</a></td><td>arXiv:2512.05167v1 Announce Type: new  Abstract: This paper presents an innovative pedagogical approach for teaching artificial intelligence and data science t‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05212" target="_blank" rel="noopener">On the Computability of Artificial General Intelligence</a></td><td>arXiv:2512.05212v1 Announce Type: new  Abstract: In recent years we observed rapid and significant advancements in artificial intelligence (A.I.). So much so t‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05257" target="_blank" rel="noopener">Resolving Zadehs Paradox Axiomatic Possibility Theory as a Foundation for Reliable Artificial Intelligence</a></td><td>arXiv:2512.05257v1 Announce Type: new  Abstract: This work advances and substantiates the thesis that the resolution of this crisis lies in the domain of possi‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05356" target="_blank" rel="noopener">AI &amp; Human Co-Improvement for Safer Co-Superintelligence</a></td><td>arXiv:2512.05356v1 Announce Type: new  Abstract: Self-improvement is a goal currently exciting the field of AI, but is fraught with danger, and may take time t‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05365" target="_blank" rel="noopener">MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare</a></td><td>arXiv:2512.05365v1 Announce Type: new  Abstract: Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state mana‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05371" target="_blank" rel="noopener">ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications</a></td><td>arXiv:2512.05371v1 Announce Type: new  Abstract: While Large Language Models (LLMs) demonstrate immense potential for automating integrated circuit (IC) develo‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05439" target="_blank" rel="noopener">BEAVER: An Efficient Deterministic LLM Verifier</a></td><td>arXiv:2512.05439v1 Announce Type: new  Abstract: As large language models (LLMs) transition from research prototypes to production systems, practitioners often‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05449" target="_blank" rel="noopener">The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems</a></td><td>arXiv:2512.05449v1 Announce Type: new  Abstract: Large language models display a peculiar form of inconsistency: they &quot;know&quot; the correct answer but fail to act‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05530" target="_blank" rel="noopener">MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models</a></td><td>arXiv:2512.05530v1 Announce Type: new  Abstract: Recently, multimodal large language models (MLLMs) have been widely applied to reasoning tasks. However, they‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05576" target="_blank" rel="noopener">CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning</a></td><td>arXiv:2512.05576v1 Announce Type: new  Abstract: Current clinical agent built on small LLMs, such as TxAgent suffer from a \textit{Context Utilization Failure}‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05594" target="_blank" rel="noopener">Ontology Learning with LLMs: A Benchmark Study on Axiom Identification</a></td><td>arXiv:2512.05594v1 Announce Type: new  Abstract: Ontologies are an important tool for structuring domain knowledge, but their development is a complex task tha‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05619" target="_blank" rel="noopener">Enhancing Local Search for MaxSAT with Deep Differentiation Clause Weighting</a></td><td>arXiv:2512.05619v1 Announce Type: new  Abstract: Partial Maximum Satisfiability (PMS) and Weighted Partial Maximum Satisfiability (WPMS) generalize Maximum Sat‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.05734" target="_blank" rel="noopener">KANFormer for Predicting Fill Probabilities via Survival Analysis in Limit Order Books</a></td><td>arXiv:2512.05734v1 Announce Type: new  Abstract: This paper introduces KANFormer, a novel deep-learning-based model for predicting the time-to-fill of limit or‚Ä¶</td><td>2025-12-08T05:00:00Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Models</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z ‚Ä¢ Source: <a href="https://huggingface.co/api/models" target="_blank" rel="noopener">https://huggingface.co/api/models</a> ‚Ä¢ Hash: <code>edb3d86947c5f8d876d9c4481cb4419a0d2e7876af7b8f691870930c02d571fc</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Model</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/Falconsai/nsfw_image_detection" target="_blank" rel="noopener">Falconsai/nsfw_image_detection</a></td><td>122866637</td><td>847</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" target="_blank" rel="noopener">sentence-transformers/all-MiniLM-L6-v2</a></td><td>118061338</td><td>4004</td></tr>
      <tr><td><a href="https://huggingface.co/dima806/fairface_age_image_detection" target="_blank" rel="noopener">dima806/fairface_age_image_detection</a></td><td>81641974</td><td>44</td></tr>
      <tr><td><a href="https://huggingface.co/google/electra-base-discriminator" target="_blank" rel="noopener">google/electra-base-discriminator</a></td><td>58549625</td><td>66</td></tr>
      <tr><td><a href="https://huggingface.co/google-bert/bert-base-uncased" target="_blank" rel="noopener">google-bert/bert-base-uncased</a></td><td>53275807</td><td>2441</td></tr>
      <tr><td><a href="https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k" target="_blank" rel="noopener">timm/mobilenetv3_small_100.lamb_in1k</a></td><td>43762365</td><td>39</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-large" target="_blank" rel="noopener">FacebookAI/roberta-large</a></td><td>20426777</td><td>250</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" target="_blank" rel="noopener">sentence-transformers/all-mpnet-base-v2</a></td><td>17830892</td><td>1170</td></tr>
      <tr><td><a href="https://huggingface.co/openai/clip-vit-base-patch32" target="_blank" rel="noopener">openai/clip-vit-base-patch32</a></td><td>17638896</td><td>782</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/segmentation-3.0" target="_blank" rel="noopener">pyannote/segmentation-3.0</a></td><td>17234148</td><td>626</td></tr>
      <tr><td><a href="https://huggingface.co/tech4humans/yolov8s-signature-detector" target="_blank" rel="noopener">tech4humans/yolov8s-signature-detector</a></td><td>16874538</td><td>48</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM" target="_blank" rel="noopener">pyannote/wespeaker-voxceleb-resnet34-LM</a></td><td>14933122</td><td>80</td></tr>
      <tr><td><a href="https://huggingface.co/Bingsu/adetailer" target="_blank" rel="noopener">Bingsu/adetailer</a></td><td>14489181</td><td>620</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-base" target="_blank" rel="noopener">FacebookAI/roberta-base</a></td><td>14321545</td><td>529</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/speaker-diarization-3.1" target="_blank" rel="noopener">pyannote/speaker-diarization-3.1</a></td><td>14186095</td><td>1228</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>GitHub Trending Repositories</h2>
  <p class="metadata">Fetched at 2025-12-08T05:36:11Z ‚Ä¢ Source: <a href="https://api.github.com/search/repositories" target="_blank" rel="noopener">https://api.github.com/search/repositories</a> ‚Ä¢ Hash: <code>3eb846ebb72a58e755a8564c227382ecb45eb02807e20e661349f87b8e34c3ce</code></p>
  <table>
    <thead>
      <tr><th>Repository</th><th>Stars</th><th>Description</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://github.com/DeNA/llm-study20251201" target="_blank" rel="noopener">DeNA/llm-study20251201</a></td><td>158</td><td>DeNAÁ§æÂÜÖ„ÅßÂÆüÊñΩ„Åó„ÅüLLMÂãâÂº∑‰ºö„ÅÆË≥áÊñô„Å®„ÇΩ„Éº„Çπ„Ç≥„Éº„Éâ</td></tr>
      <tr><td><a href="https://github.com/TakatoHonda/sui-lang" target="_blank" rel="noopener">TakatoHonda/sui-lang</a></td><td>145</td><td>Á≤ã (Sui) - A programming language optimized for LLM code generation</td></tr>
      <tr><td><a href="https://github.com/m-sec-org/ez-xbow-platform-mcp" target="_blank" rel="noopener">m-sec-org/ez-xbow-platform-mcp</a></td><td>59</td><td>‰∏Ä‰∏™Áî®‰∫é AI È©±Âä®ÁöÑÊ∏óÈÄèÊµãËØïÁ´ûËµõÁöÑ**Ê®°Âûã‰∏ä‰∏ãÊñáÂçèËÆÆ (MCP)** ÊúçÂä°Âô®„ÄÇËØ•Â∑• ÂÖ∑Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ API Êé•Âè£Ôºå‰Ωø LLM ËÉΩÂ§üËá™‰∏ªÂèÇ‰∏é CTF ÊåëÊàò„ÄÇ</td></tr>
      <tr><td><a href="https://github.com/yen-shi-lun/Krita-Ollama-Prompt-Generator" target="_blank" rel="noopener">yen-shi-lun/Krita-Ollama-Prompt-Generator</a></td><td>19</td><td>Wuhe Design presents the Krita √ó Ollama Prompt Generator ‚Äî a local LLM-powered plugin for generating, refining, and sending prompts directly into the krita-ai-‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/kylehughes/the-unofficial-swift-concurrency-migration-skill" target="_blank" rel="noopener">kylehughes/the-unofficial-swift-concurrency-migration-skill</a></td><td>18</td><td>The Swift Concurrency Migration Guide, packaged as a Skill for LLMs.</td></tr>
      <tr><td><a href="https://github.com/Glitch-Jar/LLM-EYES" target="_blank" rel="noopener">Glitch-Jar/LLM-EYES</a></td><td>14</td><td>Give LLMs eyes, then benchmark what they see</td></tr>
      <tr><td><a href="https://github.com/agynio/gh-pr-review" target="_blank" rel="noopener">agynio/gh-pr-review</a></td><td>10</td><td>LLM-optimized GitHub CLI extension for PR reviews: view reviews and threads, reply and resolve, and submit reviews.</td></tr>
      <tr><td><a href="https://github.com/devopsdymyr/Evo-Memory" target="_blank" rel="noopener">devopsdymyr/Evo-Memory</a></td><td>8</td><td>Implementation of Evo-Memory style learning for LLM agents. Agents learn from outcomes, refine strategies, and get smarter with every task.  üöÄ Features:  Exper‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/Runtime-Exception/lmprobe" target="_blank" rel="noopener">Runtime-Exception/lmprobe</a></td><td>7</td><td>Probe multiple LLM API endpoints to detect available models, then serve them through a unified local API supporting both OpenAI and Anthropic Claude formats.</td></tr>
      <tr><td><a href="https://github.com/eliteresearchlab/BRAINS" target="_blank" rel="noopener">eliteresearchlab/BRAINS</a></td><td>7</td><td>BRAINS is a production-ready, multi-agent medical diagnostic platform powered by Retrieval-Augmented Generation (RAG) and LLM inference. It combines a Next.js‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/hannahjan06/MultiBrain-AI" target="_blank" rel="noopener">hannahjan06/MultiBrain-AI</a></td><td>7</td><td>MultiBrain AI is an automated meeting assistant that transcribes audio with Whisper, generates structured notes using an LLM, and automatically creates tasks,‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/Mohamedsaleh14/ContextGit" target="_blank" rel="noopener">Mohamedsaleh14/ContextGit</a></td><td>6</td><td>Context and requirement Management tool for CLI LLM tools</td></tr>
      <tr><td><a href="https://github.com/btitkin/ComfyUI-RandomPromptBuilder" target="_blank" rel="noopener">btitkin/ComfyUI-RandomPromptBuilder</a></td><td>6</td><td>Random Prompt Builder LLM for ComfyUI</td></tr>
      <tr><td><a href="https://github.com/cameronking4/programmatic-tool-calling-ai-sdk" target="_blank" rel="noopener">cameronking4/programmatic-tool-calling-ai-sdk</a></td><td>6</td><td>‚ö° Cut LLM inference costs 80% with Programmatic Tool Calling. Instead of N tool call round-trips, generate JavaScript to orchestrate tools in Vercel Sandbox. S‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/dangehub/obsidian-translay-translator" target="_blank" rel="noopener">dangehub/obsidian-translay-translator</a></td><td>6</td><td>Ë∞ÉÁî®‰Ω†ÂñúÊ¨¢ÁöÑAIÔºàLLMÔºâÁøªËØëObsidian‰∏≠ÁöÑ‰ªª‰ΩïÊñáÊú¨ÔºåÊîØÊåÅËØçÂÖ∏ÂØºÂÖ•ÂØºÂá∫</td></tr>
      <tr><td><a href="https://github.com/matte1782/binary_semantic_cache" target="_blank" rel="noopener">matte1782/binary_semantic_cache</a></td><td>6</td><td>High‚Äëperformance semantic cache for LLMs with a Rust core, 256‚Äëbit binary embeddings, ~10‚ÄØms index load at 1M entries, and native OpenAI/Ollama integration.</td></tr>
      <tr><td><a href="https://github.com/waddadaa/gpagent" target="_blank" rel="noopener">waddadaa/gpagent</a></td><td>6</td><td>Native C++/Qt AI agent with tool use, multi-LLM support, and self-improving tool selection using Tiny Recursive Models</td></tr>
      <tr><td><a href="https://github.com/Rohitnegi9/STRIKEGenAI" target="_blank" rel="noopener">Rohitnegi9/STRIKEGenAI</a></td><td>5</td><td>This Is official documentation of Strike GenAI</td></tr>
      <tr><td><a href="https://github.com/guhatek/llm-observability" target="_blank" rel="noopener">guhatek/llm-observability</a></td><td>5</td><td>A collection of demos and documentation for end-to-end LLM observability. Track, evaluate, and debug large language models with confidence.</td></tr>
      <tr><td><a href="https://github.com/hparreao/Awesome-AI-Evaluation-Guide" target="_blank" rel="noopener">hparreao/Awesome-AI-Evaluation-Guide</a></td><td>5</td><td>A comprehensive, implementation-focused guide to evaluating Large Language Models, RAG systems, and Agentic AI in production environments.</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Papers with Code</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z ‚Ä¢ Source: <a href="https://paperswithcode.com/api/v1/papers/" target="_blank" rel="noopener">https://paperswithcode.com/api/v1/papers/</a> ‚Ä¢ Hash: <code>d4a343f7408e936b9b783882d60713e7711a2e2104b924d1a9726c2b1660e60c</code></p>
  <p class="warning">Expecting value: line 1 column 1 (char 0)</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>Hacker News Highlights</h2>
  <p class="metadata">Fetched at 2025-12-08T05:36:11Z ‚Ä¢ Source: <a href="https://hacker-news.firebaseio.com/" target="_blank" rel="noopener">https://hacker-news.firebaseio.com/</a> ‚Ä¢ Hash: <code>9f71a8693dd4791bf88385bce5a9edfa1ee6850f5fef0c4db361d569b460461a</code></p>
  <table>
    <thead>
      <tr><th>Story</th><th>Score</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://research.google/blog/titans-miras-helping-ai-have-long-term-memory/" target="_blank" rel="noopener">Google Titans architecture, helping AI have long-term memory</a></td><td>440</td><td>2025-12-07T12:23:45Z</td></tr>
      <tr><td><a href="https://ceodinner.substack.com/p/the-ai-wildfire-is-coming-its-going" target="_blank" rel="noopener">The AI wildfire is coming. it&#x27;s going to be painful and healthy</a></td><td>106</td><td>2025-12-07T16:43:38Z</td></tr>
      <tr><td><a href="https://techoreon.com/openai-disables-chatgpt-app-suggestions-ads-backlash/" target="_blank" rel="noopener">OpenAI disables ChatGPT app suggestions that looked like ads</a></td><td>66</td><td>2025-12-07T15:52:18Z</td></tr>
      <tr><td><a href="https://www.technologyreview.com/2025/12/04/1128824/ai-chatbots-can-sway-voters-better-than-political-advertisements/" target="_blank" rel="noopener">AI chatbots can sway voters better than political advertisements</a></td><td>5</td><td>2025-12-08T00:42:43Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Latest CVEs</h2>
  <p class="metadata">Fetched at 2025-12-08T05:36:11Z ‚Ä¢ Source: <a href="https://cve.circl.lu/api/last" target="_blank" rel="noopener">https://cve.circl.lu/api/last</a> ‚Ä¢ Hash: <code>83f0388b7b20583c1ae887fad1d1f83bc654e67c4b904262da02c600faa6afbe</code></p>
  <table>
    <thead>
      <tr><th>CVE</th><th>CVSS</th><th>Summary</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-191977" target="_blank" rel="noopener">MAL-2025-191977</a></td><td>0.0</td><td>Malicious code in elf-stats-rooftop-stockpile-626 (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-191980" target="_blank" rel="noopener">MAL-2025-191980</a></td><td>0.0</td><td>Malicious code in elf-stats-cosy-sleigh-356 (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-2989-gqx8-wgwx" target="_blank" rel="noopener">GHSA-2989-gqx8-wgwx</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-hgww-pjhr-mwxr" target="_blank" rel="noopener">GHSA-hgww-pjhr-mwxr</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-j7cr-m6w2-c634" target="_blank" rel="noopener">GHSA-j7cr-m6w2-c634</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-pfq8-pr42-5qc2" target="_blank" rel="noopener">GHSA-pfq8-pr42-5qc2</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-phff-w2xw-v2wg" target="_blank" rel="noopener">GHSA-phff-w2xw-v2wg</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-qjv9-pc7w-9xrj" target="_blank" rel="noopener">GHSA-qjv9-pc7w-9xrj</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-qr5m-r7jf-6jc5" target="_blank" rel="noopener">GHSA-qr5m-r7jf-6jc5</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-r2g2-5w3q-5hqj" target="_blank" rel="noopener">GHSA-r2g2-5w3q-5hqj</a></td><td>0.0</td><td></td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Datasets</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z ‚Ä¢ Source: <a href="https://huggingface.co/api/datasets" target="_blank" rel="noopener">https://huggingface.co/api/datasets</a> ‚Ä¢ Hash: <code>4b4cc33871c4b3cd497c500155aa79f37885aa24df2d895e1d18c0c80ab6ae9c</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Dataset</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/datasets/nebius/SWE-rebench" target="_blank" rel="noopener">nebius/SWE-rebench</a></td><td>3717252</td><td>35</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/SWE-Gym/SWE-Gym" target="_blank" rel="noopener">SWE-Gym/SWE-Gym</a></td><td>2041687</td><td>20</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/huggingface/documentation-images" target="_blank" rel="noopener">huggingface/documentation-images</a></td><td>2014781</td><td>86</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/chcorbi/helvipad" target="_blank" rel="noopener">chcorbi/helvipad</a></td><td>1478443</td><td>10</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/AquaV/genshin-voices-separated" target="_blank" rel="noopener">AquaV/genshin-voices-separated</a></td><td>1461805</td><td>8</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/banned-historical-archives/banned-historical-archives" target="_blank" rel="noopener">banned-historical-archives/banned-historical-archives</a></td><td>1411450</td><td>5</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim" target="_blank" rel="noopener">nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim</a></td><td>1339503</td><td>155</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/princeton-nlp/SWE-bench_Verified" target="_blank" rel="noopener">princeton-nlp/SWE-bench_Verified</a></td><td>1282494</td><td>218</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/lavita/medical-qa-shared-task-v1-toy" target="_blank" rel="noopener">lavita/medical-qa-shared-task-v1-toy</a></td><td>878541</td><td>21</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/Salesforce/wikitext" target="_blank" rel="noopener">Salesforce/wikitext</a></td><td>867174</td><td>505</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/language_table_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/language_table_lerobot</a></td><td>786287</td><td>0</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/droid_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/droid_lerobot</a></td><td>737114</td><td>6</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/hf-doc-build/doc-build" target="_blank" rel="noopener">hf-doc-build/doc-build</a></td><td>671848</td><td>12</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/applied-ai-018/pretraining_v1-omega_books" target="_blank" rel="noopener">applied-ai-018/pretraining_v1-omega_books</a></td><td>614296</td><td>2</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu" target="_blank" rel="noopener">HuggingFaceFW/fineweb-edu</a></td><td>597646</td><td>775</td></tr>
    </tbody>
  </table>
</section>
  </main>
  <footer><p>Datasets updated as part of the DeepTech Daily automation run.</p><p>Last refreshed at 2025-12-08T05:36:11Z.</p><ul><li><a href="../deeptech-daily/data/gpu_prices.json">gpu_prices.json</a></li><li><a href="../deeptech-daily/data/arxiv.yaml">arxiv.yaml</a></li><li><a href="../deeptech-daily/data/hf_trending.yaml">hf_trending.yaml</a></li><li><a href="../deeptech-daily/data/github_trending.yaml">github_trending.yaml</a></li><li><a href="../deeptech-daily/data/pwc_llm.yaml">pwc_llm.yaml</a></li><li><a href="../deeptech-daily/data/hn_ai.yaml">hn_ai.yaml</a></li><li><a href="../deeptech-daily/data/cves.yaml">cves.yaml</a></li><li><a href="../deeptech-daily/data/hf_datasets.yaml">hf_datasets.yaml</a></li></ul></footer>
</body>
</html>
