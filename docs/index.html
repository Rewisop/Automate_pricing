<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>DeepTech Daily Dashboard</title>
  <style>
body { font-family: 'Inter', 'Segoe UI', system-ui, -apple-system, sans-serif; margin: 0; padding: 0; background: #0f172a; color: #e2e8f0; }
header { padding: 2.5rem 1.5rem; text-align: center; background: #1e293b; }
header h1 { margin: 0 0 0.5rem; font-size: 2.5rem; }
header p { margin: 0; color: #94a3b8; font-size: 1rem; }
main { max-width: 1100px; margin: 0 auto; padding: 2rem 1.5rem 4rem; }
section { background: rgba(15, 23, 42, 0.75); border: 1px solid rgba(148, 163, 184, 0.2); border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 12px 24px rgba(15, 23, 42, 0.4); }
section h2 { margin-top: 0; color: #f8fafc; font-size: 1.5rem; }
table { width: 100%; border-collapse: collapse; margin-top: 1rem; }
th, td { text-align: left; padding: 0.65rem 0.75rem; border-bottom: 1px solid rgba(148, 163, 184, 0.2); }
th { background: rgba(148, 163, 184, 0.1); color: #e2e8f0; font-weight: 600; }
tr:hover td { background: rgba(59, 130, 246, 0.08); }
a { color: #38bdf8; text-decoration: none; }
a:hover { text-decoration: underline; }
.warning { margin: 0.75rem 0; color: #fbbf24; }
.empty { margin: 1rem 0 0; color: #94a3b8; font-style: italic; }
.metadata { margin: 0.35rem 0 0; color: #94a3b8; font-size: 0.9rem; }
footer { text-align: center; padding: 2rem 1.5rem 3rem; color: #64748b; font-size: 0.9rem; }
footer ul { list-style: none; padding: 0; margin: 1rem 0 0; display: flex; flex-wrap: wrap; gap: 0.75rem; justify-content: center; }
footer li { background: rgba(148, 163, 184, 0.1); border-radius: 6px; padding: 0.4rem 0.75rem; }
</style>
</head>
<body>
  <header>
    <h1>DeepTech Daily Dashboard</h1>
    <p>A curated snapshot of GPUs, research, software, and security intel powered by the DeepTech Daily datasets.</p>
  </header>
  <main>
    <section>
  <h2>GPU Pricing Snapshot</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z ‚Ä¢ Source: <a href="https://vast.ai/api/v0/bundles/public" target="_blank" rel="noopener">https://vast.ai/api/v0/bundles/public</a>, <a href="https://api.runpod.io" target="_blank" rel="noopener">https://api.runpod.io</a>, <a href="https://modal.com/api" target="_blank" rel="noopener">https://modal.com/api</a> ‚Ä¢ Hash: <code>73cd0d24819c38ed4bb8d48de66e8dd1013b8b60870640a96bc6c90d3b6d6974</code></p>
  <p class="warning">Vast.ai: 404 Client Error: Not Found for url: https://console.vast.ai/api/v0/bundles/public/?limit=200&amp;skip=0</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>arXiv Digest</h2>
  <p class="metadata">Fetched at 2025-12-05T05:34:18Z ‚Ä¢ Source: <a href="https://export.arxiv.org/rss/cs.AI" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.AI</a>, <a href="https://export.arxiv.org/rss/cs.CL" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.CL</a>, <a href="https://export.arxiv.org/rss/cs.LG" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.LG</a> ‚Ä¢ Hash: <code>4172185625bf96567cb8c981ba97a3dedec5b850c6fdbfcc42c3c1ae26d7583d</code></p>
  <p class="warning">no arXiv entries retrieved</p>
  <table>
    <thead>
      <tr><th>Title</th><th>Summary</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://arxiv.org/abs/2512.03048" target="_blank" rel="noopener">Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation</a></td><td>arXiv:2512.03048v1 Announce Type: new  Abstract: I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through p‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03072" target="_blank" rel="noopener">Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI</a></td><td>arXiv:2512.03072v1 Announce Type: new  Abstract: Current AI paradigms, as &quot;architects of experience,&quot; face fundamental challenges in explainability and value a‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03272" target="_blank" rel="noopener">When Do Symbolic Solvers Enhance Reasoning in Large Language Models?</a></td><td>arXiv:2512.03272v1 Announce Type: new  Abstract: Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03293" target="_blank" rel="noopener">Prior preferences in active inference agents: soft, hard, and goal shaping</a></td><td>arXiv:2512.03293v1 Announce Type: new  Abstract: Active inference proposes expected free energy as an objective for planning and decision-making to adequately‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03318" target="_blank" rel="noopener">Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia</a></td><td>arXiv:2512.03318v1 Announce Type: new  Abstract: Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are inc‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03438" target="_blank" rel="noopener">Multimodal Reinforcement Learning with Agentic Verifier for AI Agents</a></td><td>arXiv:2512.03438v1 Announce Type: new  Abstract: Agentic reasoning models trained with multimodal reinforcement learning (MMRL) have become increasingly capabl‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03528" target="_blank" rel="noopener">Multi-Agent Reinforcement Learning with Communication-Constrained Priors</a></td><td>arXiv:2512.03528v1 Announce Type: new  Abstract: Communication is one of the effective means to improve the learning of cooperative policy in multi-agent syste‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03549" target="_blank" rel="noopener">PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks</a></td><td>arXiv:2512.03549v1 Announce Type: new  Abstract: We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks.‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03560" target="_blank" rel="noopener">Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks</a></td><td>arXiv:2512.03560v1 Announce Type: new  Abstract: Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that re‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03571" target="_blank" rel="noopener">EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths</a></td><td>arXiv:2512.03571v1 Announce Type: new  Abstract: We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to a‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03607" target="_blank" rel="noopener">DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization</a></td><td>arXiv:2512.03607v1 Announce Type: new  Abstract: This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortm‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03627" target="_blank" rel="noopener">MemVerse: Multimodal Memory for Lifelong Learning Agents</a></td><td>arXiv:2512.03627v1 Announce Type: new  Abstract: Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental li‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03762" target="_blank" rel="noopener">RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design</a></td><td>arXiv:2512.03762v2 Announce Type: new  Abstract: Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimiz‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03783" target="_blank" rel="noopener">Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning</a></td><td>arXiv:2512.03783v2 Announce Type: new  Abstract: Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existi‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.03887" target="_blank" rel="noopener">A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)</a></td><td>arXiv:2512.03887v2 Announce Type: new  Abstract: The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Rese‚Ä¶</td><td>2025-12-05T05:00:00Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Models</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z ‚Ä¢ Source: <a href="https://huggingface.co/api/models" target="_blank" rel="noopener">https://huggingface.co/api/models</a> ‚Ä¢ Hash: <code>edb3d86947c5f8d876d9c4481cb4419a0d2e7876af7b8f691870930c02d571fc</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Model</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/Falconsai/nsfw_image_detection" target="_blank" rel="noopener">Falconsai/nsfw_image_detection</a></td><td>122866637</td><td>847</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" target="_blank" rel="noopener">sentence-transformers/all-MiniLM-L6-v2</a></td><td>118061338</td><td>4004</td></tr>
      <tr><td><a href="https://huggingface.co/dima806/fairface_age_image_detection" target="_blank" rel="noopener">dima806/fairface_age_image_detection</a></td><td>81641974</td><td>44</td></tr>
      <tr><td><a href="https://huggingface.co/google/electra-base-discriminator" target="_blank" rel="noopener">google/electra-base-discriminator</a></td><td>58549625</td><td>66</td></tr>
      <tr><td><a href="https://huggingface.co/google-bert/bert-base-uncased" target="_blank" rel="noopener">google-bert/bert-base-uncased</a></td><td>53275807</td><td>2441</td></tr>
      <tr><td><a href="https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k" target="_blank" rel="noopener">timm/mobilenetv3_small_100.lamb_in1k</a></td><td>43762365</td><td>39</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-large" target="_blank" rel="noopener">FacebookAI/roberta-large</a></td><td>20426777</td><td>250</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" target="_blank" rel="noopener">sentence-transformers/all-mpnet-base-v2</a></td><td>17830892</td><td>1170</td></tr>
      <tr><td><a href="https://huggingface.co/openai/clip-vit-base-patch32" target="_blank" rel="noopener">openai/clip-vit-base-patch32</a></td><td>17638896</td><td>782</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/segmentation-3.0" target="_blank" rel="noopener">pyannote/segmentation-3.0</a></td><td>17234148</td><td>626</td></tr>
      <tr><td><a href="https://huggingface.co/tech4humans/yolov8s-signature-detector" target="_blank" rel="noopener">tech4humans/yolov8s-signature-detector</a></td><td>16874538</td><td>48</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM" target="_blank" rel="noopener">pyannote/wespeaker-voxceleb-resnet34-LM</a></td><td>14933122</td><td>80</td></tr>
      <tr><td><a href="https://huggingface.co/Bingsu/adetailer" target="_blank" rel="noopener">Bingsu/adetailer</a></td><td>14489181</td><td>620</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-base" target="_blank" rel="noopener">FacebookAI/roberta-base</a></td><td>14321545</td><td>529</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/speaker-diarization-3.1" target="_blank" rel="noopener">pyannote/speaker-diarization-3.1</a></td><td>14186095</td><td>1228</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>GitHub Trending Repositories</h2>
  <p class="metadata">Fetched at 2025-12-06T05:32:09Z ‚Ä¢ Source: <a href="https://api.github.com/search/repositories" target="_blank" rel="noopener">https://api.github.com/search/repositories</a> ‚Ä¢ Hash: <code>027abc6101800b4df7bfee8269210adcb1e8b3d57e8b49733d1a32b47a976c4b</code></p>
  <table>
    <thead>
      <tr><th>Repository</th><th>Stars</th><th>Description</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://github.com/aeitroc/claude-select" target="_blank" rel="noopener">aeitroc/claude-select</a></td><td>86</td><td>A unified launcher for Claude Code that lets you interactively choose which LLM backend to use.</td></tr>
      <tr><td><a href="https://github.com/maruhan12-max/AI-Compliance-Failure-Patterns" target="_blank" rel="noopener">maruhan12-max/AI-Compliance-Failure-Patterns</a></td><td>63</td><td>ÏßÄÏãú Î∂àÏù¥Ìñâ(Instruction Non-Compliance) ÌòÑÏÉÅÏùÑ Ïú†Î∞úÌïòÎäî ÌîÑÎ°¨ÌîÑÌä∏ Ìå®ÌÑ¥ 11Í∞ÄÏßÄ(A-K) - ChatGPT, Gemini Îì± Ï£ºÏöî LLM Î™®Îç∏Îì§Ïùò Ï∑®ÏïΩÏÑ± Î∞è Ï†ïÏ±Ö Ï∂©Îèå ÎåÄÏùë Î∞©ÏãùÏùÑ ÎπÑÍµê Î∂ÑÏÑù ÌîÑÎ°úÏ†ùÌä∏</td></tr>
      <tr><td><a href="https://github.com/m-sec-org/ez-xbow-platform-mcp" target="_blank" rel="noopener">m-sec-org/ez-xbow-platform-mcp</a></td><td>58</td><td>‰∏Ä‰∏™Áî®‰∫é AI È©±Âä®ÁöÑÊ∏óÈÄèÊµãËØïÁ´ûËµõÁöÑ**Ê®°Âûã‰∏ä‰∏ãÊñáÂçèËÆÆ (MCP)** ÊúçÂä°Âô®„ÄÇËØ•Â∑• ÂÖ∑Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ API Êé•Âè£Ôºå‰Ωø LLM ËÉΩÂ§üËá™‰∏ªÂèÇ‰∏é CTF ÊåëÊàò„ÄÇ</td></tr>
      <tr><td><a href="https://github.com/TakatoHonda/sui-lang" target="_blank" rel="noopener">TakatoHonda/sui-lang</a></td><td>57</td><td>Á≤ã (Sui) - A programming language optimized for LLM code generation</td></tr>
      <tr><td><a href="https://github.com/NullStarrySky/Pulsar" target="_blank" rel="noopener">NullStarrySky/Pulsar</a></td><td>45</td><td>Áé∞‰ª£ÂåñÔºåÊ®°ÂùóÂåñÔºåÂº∫Â§ßÁöÑLLMÂØπËØùÂâçÁ´Ø</td></tr>
      <tr><td><a href="https://github.com/broalantaps/Awesome-Context-Compression-LLMs" target="_blank" rel="noopener">broalantaps/Awesome-Context-Compression-LLMs</a></td><td>33</td><td>üöÄ A curated list of awesome resources focusing on Context Compression techniques for Large Language Models(LLMs).</td></tr>
      <tr><td><a href="https://github.com/ZJU-LLMs/Agent-Kernel" target="_blank" rel="noopener">ZJU-LLMs/Agent-Kernel</a></td><td>28</td><td>A MicroKernel Multi-Agents System Framework for Adaptive Social Simulation Powered by LLMs</td></tr>
      <tr><td><a href="https://github.com/WhiskeyCoder/HomeLab-Log-Analyzer" target="_blank" rel="noopener">WhiskeyCoder/HomeLab-Log-Analyzer</a></td><td>18</td><td>A fully-local, fully-automated system that turns your chaotic Docker logs into clean, structured, actionable intelligence, every night, powered by your own loc‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/JhCircle/Kardia-R1" target="_blank" rel="noopener">JhCircle/Kardia-R1</a></td><td>17</td><td>Kardia-R1: Unleashing LLMs to Reason toward Understanding and Empathy for Emotional Support via Rubric-as-Judge Reinforcement Learning</td></tr>
      <tr><td><a href="https://github.com/lern-to-write/STC" target="_blank" rel="noopener">lern-to-write/STC</a></td><td>16</td><td>Accelerating Streaming Video Large Language Models via Hierarchical Token Compression</td></tr>
      <tr><td><a href="https://github.com/wisent-ai/uncensorbench" target="_blank" rel="noopener">wisent-ai/uncensorbench</a></td><td>15</td><td>A benchmark for measuring LLM censorship removal effectiveness</td></tr>
      <tr><td><a href="https://github.com/facebookresearch/prompt-siren" target="_blank" rel="noopener">facebookresearch/prompt-siren</a></td><td>14</td><td>A research workbench for developing and testing attacks against large language models, with a focus on prompt injection vulnerabilities and defenses.</td></tr>
      <tr><td><a href="https://github.com/STAR-173/LLMSession-Docker" target="_blank" rel="noopener">STAR-173/LLMSession-Docker</a></td><td>12</td><td>A unified REST API that wraps web-based LLM sessions (ChatGPT, Claude, Google AI Studio) into a standard interface using headless automation. Access your web-t‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/ibrahim-ansari-code/LLM-Council-IDE" target="_blank" rel="noopener">ibrahim-ansari-code/LLM-Council-IDE</a></td><td>11</td><td>Drawing inspiration from Andrej Karpathy&#x27;s LLM Council, this is an implementation for coding. LLMs evaluate each other and generate the best result rather than‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/Ge-limin/ai-native-engineering-manifesto" target="_blank" rel="noopener">Ge-limin/ai-native-engineering-manifesto</a></td><td>10</td><td>A manifesto and playbook for AI-native software engineering in the LLM era / AI-NativeÁöÑËΩØ‰ª∂Â∑•Á®ãÂÆ£Ë®Ä</td></tr>
      <tr><td><a href="https://github.com/ML-GSAI/ESPO" target="_blank" rel="noopener">ML-GSAI/ESPO</a></td><td>9</td><td>Official PyTorch implementation for &quot;Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective&quot;</td></tr>
      <tr><td><a href="https://github.com/hannahjan06/MultiBrain-AI" target="_blank" rel="noopener">hannahjan06/MultiBrain-AI</a></td><td>7</td><td>MultiBrain AI is an automated meeting assistant that transcribes audio with Whisper, generates structured notes using an LLM, and automatically creates tasks,‚Ä¶</td></tr>
      <tr><td><a href="https://github.com/Mohamedsaleh14/ContextGit" target="_blank" rel="noopener">Mohamedsaleh14/ContextGit</a></td><td>6</td><td>Context and requirement Management tool for CLI LLM tools</td></tr>
      <tr><td><a href="https://github.com/btitkin/ComfyUI-RandomPromptBuilder" target="_blank" rel="noopener">btitkin/ComfyUI-RandomPromptBuilder</a></td><td>6</td><td>Random Prompt Builder LLM for ComfyUI</td></tr>
      <tr><td><a href="https://github.com/ethicals7s/awesome-local-ai" target="_blank" rel="noopener">ethicals7s/awesome-local-ai</a></td><td>6</td><td>152 open-source tools to run LLMs 100% locally ‚Äì no cloud, no API keys, no censorship</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Papers with Code</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z ‚Ä¢ Source: <a href="https://paperswithcode.com/api/v1/papers/" target="_blank" rel="noopener">https://paperswithcode.com/api/v1/papers/</a> ‚Ä¢ Hash: <code>d4a343f7408e936b9b783882d60713e7711a2e2104b924d1a9726c2b1660e60c</code></p>
  <p class="warning">Expecting value: line 1 column 1 (char 0)</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>Hacker News Highlights</h2>
  <p class="metadata">Fetched at 2025-12-06T05:32:09Z ‚Ä¢ Source: <a href="https://hacker-news.firebaseio.com/" target="_blank" rel="noopener">https://hacker-news.firebaseio.com/</a> ‚Ä¢ Hash: <code>03866ee2f8a1225a512b7601a4e9420a28b5f4c00547627c41f884f8dce9e2ee</code></p>
  <table>
    <thead>
      <tr><th>Story</th><th>Score</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://blog.google/technology/developers/gemini-3-pro-vision/" target="_blank" rel="noopener">Gemini 3 Pro: the frontier of vision AI</a></td><td>394</td><td>2025-12-05T16:15:10Z</td></tr>
      <tr><td><a href="https://www.ynetnews.com/tech-and-digital/article/bj1qbwcklg" target="_blank" rel="noopener">YouTube caught making AI-edits to videos and adding misleading AI summaries</a></td><td>191</td><td>2025-12-06T01:15:48Z</td></tr>
      <tr><td><a href="https://www.macrumors.com/2025/12/05/openai-device-barred-from-io-name/" target="_blank" rel="noopener">Jony Ive&#x27;s OpenAI Device Barred From Using &#x27;io&#x27; Name</a></td><td>81</td><td>2025-12-05T16:48:44Z</td></tr>
      <tr><td><a href="https://rollingout.com/2025/12/05/wall-street-protects-itself-ai-bubble/" target="_blank" rel="noopener">Wall Street races to protect itself from AI bubble</a></td><td>67</td><td>2025-12-05T18:21:43Z</td></tr>
      <tr><td><a href="https://www.ft.com/content/f2e03bd9-af67-45c4-8e1e-79978b5bc48f" target="_blank" rel="noopener">AI led to an increase in radiologists, not a decrease</a></td><td>12</td><td>2025-12-05T20:10:57Z</td></tr>
      <tr><td><a href="https://github.com/rsionnach/sloppylint" target="_blank" rel="noopener">Show HN: Sloppylint ‚Äì A linter for AI-generated Python code</a></td><td>9</td><td>2025-12-05T21:36:42Z</td></tr>
      <tr><td><a href="https://www.raf.xyz/blog/03-how-i-keep-up-with-ai-generated-prs" target="_blank" rel="noopener">How I keep up with AI-generated PRs</a></td><td>6</td><td>2025-12-05T22:15:20Z</td></tr>
      <tr><td><a href="https://riskparody.substack.com/p/the-agentic-ai-trade-is-stalling" target="_blank" rel="noopener">The &quot;Agentic AI&quot; Trade Is Stalling</a></td><td>5</td><td>2025-12-05T23:18:31Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Latest CVEs</h2>
  <p class="metadata">Fetched at 2025-12-06T05:32:09Z ‚Ä¢ Source: <a href="https://cve.circl.lu/api/last" target="_blank" rel="noopener">https://cve.circl.lu/api/last</a> ‚Ä¢ Hash: <code>d44254d415ad1e49a9fd60575afc2e27a37ba9a6f01d41eb07e11a82de34a4ed</code></p>
  <table>
    <thead>
      <tr><th>CVE</th><th>CVSS</th><th>Summary</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2024-32959" target="_blank" rel="noopener">CVE-2024-32959</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-8cr7-x5g8-m3f3" target="_blank" rel="noopener">GHSA-8cr7-x5g8-m3f3</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-vgjg-5wh9-2grq" target="_blank" rel="noopener">GHSA-vgjg-5wh9-2grq</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-23367" target="_blank" rel="noopener">CVE-2025-23367</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-q469-433j-8xc2" target="_blank" rel="noopener">GHSA-q469-433j-8xc2</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-54236" target="_blank" rel="noopener">CVE-2025-54236</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-59820" target="_blank" rel="noopener">CVE-2025-59820</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-r8j3-whr2-75m5" target="_blank" rel="noopener">GHSA-r8j3-whr2-75m5</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-65844" target="_blank" rel="noopener">CVE-2025-65844</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-55182" target="_blank" rel="noopener">CVE-2025-55182</a></td><td>0.0</td><td></td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Datasets</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z ‚Ä¢ Source: <a href="https://huggingface.co/api/datasets" target="_blank" rel="noopener">https://huggingface.co/api/datasets</a> ‚Ä¢ Hash: <code>4b4cc33871c4b3cd497c500155aa79f37885aa24df2d895e1d18c0c80ab6ae9c</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Dataset</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/datasets/nebius/SWE-rebench" target="_blank" rel="noopener">nebius/SWE-rebench</a></td><td>3717252</td><td>35</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/SWE-Gym/SWE-Gym" target="_blank" rel="noopener">SWE-Gym/SWE-Gym</a></td><td>2041687</td><td>20</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/huggingface/documentation-images" target="_blank" rel="noopener">huggingface/documentation-images</a></td><td>2014781</td><td>86</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/chcorbi/helvipad" target="_blank" rel="noopener">chcorbi/helvipad</a></td><td>1478443</td><td>10</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/AquaV/genshin-voices-separated" target="_blank" rel="noopener">AquaV/genshin-voices-separated</a></td><td>1461805</td><td>8</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/banned-historical-archives/banned-historical-archives" target="_blank" rel="noopener">banned-historical-archives/banned-historical-archives</a></td><td>1411450</td><td>5</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim" target="_blank" rel="noopener">nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim</a></td><td>1339503</td><td>155</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/princeton-nlp/SWE-bench_Verified" target="_blank" rel="noopener">princeton-nlp/SWE-bench_Verified</a></td><td>1282494</td><td>218</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/lavita/medical-qa-shared-task-v1-toy" target="_blank" rel="noopener">lavita/medical-qa-shared-task-v1-toy</a></td><td>878541</td><td>21</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/Salesforce/wikitext" target="_blank" rel="noopener">Salesforce/wikitext</a></td><td>867174</td><td>505</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/language_table_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/language_table_lerobot</a></td><td>786287</td><td>0</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/droid_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/droid_lerobot</a></td><td>737114</td><td>6</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/hf-doc-build/doc-build" target="_blank" rel="noopener">hf-doc-build/doc-build</a></td><td>671848</td><td>12</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/applied-ai-018/pretraining_v1-omega_books" target="_blank" rel="noopener">applied-ai-018/pretraining_v1-omega_books</a></td><td>614296</td><td>2</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu" target="_blank" rel="noopener">HuggingFaceFW/fineweb-edu</a></td><td>597646</td><td>775</td></tr>
    </tbody>
  </table>
</section>
  </main>
  <footer><p>Datasets updated as part of the DeepTech Daily automation run.</p><p>Last refreshed at 2025-12-06T05:32:09Z.</p><ul><li><a href="../deeptech-daily/data/gpu_prices.json">gpu_prices.json</a></li><li><a href="../deeptech-daily/data/arxiv.yaml">arxiv.yaml</a></li><li><a href="../deeptech-daily/data/hf_trending.yaml">hf_trending.yaml</a></li><li><a href="../deeptech-daily/data/github_trending.yaml">github_trending.yaml</a></li><li><a href="../deeptech-daily/data/pwc_llm.yaml">pwc_llm.yaml</a></li><li><a href="../deeptech-daily/data/hn_ai.yaml">hn_ai.yaml</a></li><li><a href="../deeptech-daily/data/cves.yaml">cves.yaml</a></li><li><a href="../deeptech-daily/data/hf_datasets.yaml">hf_datasets.yaml</a></li></ul></footer>
</body>
</html>
