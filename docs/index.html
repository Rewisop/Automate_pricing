<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>DeepTech Daily Dashboard</title>
  <style>
body { font-family: 'Inter', 'Segoe UI', system-ui, -apple-system, sans-serif; margin: 0; padding: 0; background: #0f172a; color: #e2e8f0; }
header { padding: 2.5rem 1.5rem; text-align: center; background: #1e293b; }
header h1 { margin: 0 0 0.5rem; font-size: 2.5rem; }
header p { margin: 0; color: #94a3b8; font-size: 1rem; }
main { max-width: 1100px; margin: 0 auto; padding: 2rem 1.5rem 4rem; }
section { background: rgba(15, 23, 42, 0.75); border: 1px solid rgba(148, 163, 184, 0.2); border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 12px 24px rgba(15, 23, 42, 0.4); }
section h2 { margin-top: 0; color: #f8fafc; font-size: 1.5rem; }
table { width: 100%; border-collapse: collapse; margin-top: 1rem; }
th, td { text-align: left; padding: 0.65rem 0.75rem; border-bottom: 1px solid rgba(148, 163, 184, 0.2); }
th { background: rgba(148, 163, 184, 0.1); color: #e2e8f0; font-weight: 600; }
tr:hover td { background: rgba(59, 130, 246, 0.08); }
a { color: #38bdf8; text-decoration: none; }
a:hover { text-decoration: underline; }
.warning { margin: 0.75rem 0; color: #fbbf24; }
.empty { margin: 1rem 0 0; color: #94a3b8; font-style: italic; }
.metadata { margin: 0.35rem 0 0; color: #94a3b8; font-size: 0.9rem; }
footer { text-align: center; padding: 2rem 1.5rem 3rem; color: #64748b; font-size: 0.9rem; }
footer ul { list-style: none; padding: 0; margin: 1rem 0 0; display: flex; flex-wrap: wrap; gap: 0.75rem; justify-content: center; }
footer li { background: rgba(148, 163, 184, 0.1); border-radius: 6px; padding: 0.4rem 0.75rem; }
</style>
</head>
<body>
  <header>
    <h1>DeepTech Daily Dashboard</h1>
    <p>A curated snapshot of GPUs, research, software, and security intel powered by the DeepTech Daily datasets.</p>
  </header>
  <main>
    <section>
  <h2>GPU Pricing Snapshot</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z • Source: <a href="https://vast.ai/api/v0/bundles/public" target="_blank" rel="noopener">https://vast.ai/api/v0/bundles/public</a>, <a href="https://api.runpod.io" target="_blank" rel="noopener">https://api.runpod.io</a>, <a href="https://modal.com/api" target="_blank" rel="noopener">https://modal.com/api</a> • Hash: <code>73cd0d24819c38ed4bb8d48de66e8dd1013b8b60870640a96bc6c90d3b6d6974</code></p>
  <p class="warning">Vast.ai: 404 Client Error: Not Found for url: https://console.vast.ai/api/v0/bundles/public/?limit=200&amp;skip=0</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>arXiv Digest</h2>
  <p class="metadata">Fetched at 2025-12-10T05:35:36Z • Source: <a href="https://export.arxiv.org/rss/cs.AI" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.AI</a>, <a href="https://export.arxiv.org/rss/cs.CL" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.CL</a>, <a href="https://export.arxiv.org/rss/cs.LG" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.LG</a> • Hash: <code>285205d478d64290fbd8a66e6fd2f42f59c622468a4a7dabd7cae245b47a9960</code></p>
  <table>
    <thead>
      <tr><th>Title</th><th>Summary</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://arxiv.org/abs/2512.07841" target="_blank" rel="noopener">Impact of Data-Oriented and Object-Oriented Design on Performance and Cache Utilization with Artificial Intelligence Algorithms in Multi-Threaded CPUs</a></td><td>arXiv:2512.07841v1 Announce Type: new  Abstract: The growing performance gap between multi-core CPUs and main memory necessitates hardware-aware software desig…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.07926" target="_blank" rel="noopener">Can AI autonomously build, operate, and use the entire data stack?</a></td><td>arXiv:2512.07926v1 Announce Type: new  Abstract: Enterprise data management is a monumental task. It spans data architecture and systems, integration, quality,…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.07993" target="_blank" rel="noopener">SkipKV: Selective Skipping of KV Generation and Storage for Efficient Inference with Large Reasoning Models</a></td><td>arXiv:2512.07993v1 Announce Type: new  Abstract: Large reasoning models (LRMs) often cost significant key-value (KV) cache overhead, due to their linear growth…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.08026" target="_blank" rel="noopener">Toward an AI Reasoning-Enabled System for Patient-Clinical Trial Matching</a></td><td>arXiv:2512.08026v1 Announce Type: new  Abstract: Screening patients for clinical trial eligibility remains a manual, time-consuming, and resource-intensive pro…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.08057" target="_blank" rel="noopener">Large Language Models for Education and Research: An Empirical and User Survey-based Analysis</a></td><td>arXiv:2512.08057v1 Announce Type: new  Abstract: Pretrained Large Language Models (LLMs) have achieved remarkable success across diverse domains, with educatio…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.08147" target="_blank" rel="noopener">Scalable Back-End for an AI-Based Diabetes Prediction Application</a></td><td>arXiv:2512.08147v1 Announce Type: new  Abstract: The rising global prevalence of diabetes necessitates early detection to prevent severe complications. While A…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.08230" target="_blank" rel="noopener">Empowerment Gain and Causal Model Construction: Children and adults are sensitive to controllability and variability in their causal interventions</a></td><td>arXiv:2512.08230v1 Announce Type: new  Abstract: Learning about the causal structure of the world is a fundamental problem for human cognition. Causal models a…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.08261" target="_blank" rel="noopener">Beyond Traditional Diagnostics: Transforming Patient-Side Information into Predictive Insights with Knowledge Graphs and Prototypes</a></td><td>arXiv:2512.08261v1 Announce Type: new  Abstract: Predicting diseases solely from patient-side information, such as demographics and self-reported symptoms, has…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.08270" target="_blank" rel="noopener">Reasoning Models Ace the CFA Exams</a></td><td>arXiv:2512.08270v1 Announce Type: new  Abstract: Previous research has reported that large language models (LLMs) demonstrate poor performance on the Chartered…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.08273" target="_blank" rel="noopener">AgentEval: Generative Agents as Reliable Proxies for Human Evaluation of AI-Generated Content</a></td><td>arXiv:2512.08273v1 Announce Type: new  Abstract: Modern businesses are increasingly challenged by the time and expense required to generate and assess high-qua…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.08296" target="_blank" rel="noopener">Towards a Science of Scaling Agent Systems</a></td><td>arXiv:2512.08296v1 Announce Type: new  Abstract: Agents, language model (LM)-based systems that are capable of reasoning, planning, and acting are becoming the…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.08300" target="_blank" rel="noopener">rSIM: Incentivizing Reasoning Capabilities of LLMs via Reinforced Strategy Injection</a></td><td>arXiv:2512.08300v1 Announce Type: new  Abstract: Large language models (LLMs) are post-trained through reinforcement learning (RL) to evolve into Reasoning Lan…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.08340" target="_blank" rel="noopener">Predicting California Bearing Ratio with Ensemble and Neural Network Models: A Case Study from T\&quot;urkiye</a></td><td>arXiv:2512.08340v1 Announce Type: new  Abstract: The California Bearing Ratio (CBR) is a key geotechnical indicator used to assess the load-bearing capacity of…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.08343" target="_blank" rel="noopener">Soil Compaction Parameters Prediction Based on Automated Machine Learning Approach</a></td><td>arXiv:2512.08343v1 Announce Type: new  Abstract: Soil compaction is critical in construction engineering to ensure the stability of structures like road embank…</td><td>2025-12-10T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2512.08344" target="_blank" rel="noopener">Enhancing Explainability of Graph Neural Networks Through Conceptual and Structural Analyses and Their Extensions</a></td><td>arXiv:2512.08344v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) have become a powerful tool for modeling and analyzing data with graph structures…</td><td>2025-12-10T05:00:00Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Models</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z • Source: <a href="https://huggingface.co/api/models" target="_blank" rel="noopener">https://huggingface.co/api/models</a> • Hash: <code>edb3d86947c5f8d876d9c4481cb4419a0d2e7876af7b8f691870930c02d571fc</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Model</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/Falconsai/nsfw_image_detection" target="_blank" rel="noopener">Falconsai/nsfw_image_detection</a></td><td>122866637</td><td>847</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" target="_blank" rel="noopener">sentence-transformers/all-MiniLM-L6-v2</a></td><td>118061338</td><td>4004</td></tr>
      <tr><td><a href="https://huggingface.co/dima806/fairface_age_image_detection" target="_blank" rel="noopener">dima806/fairface_age_image_detection</a></td><td>81641974</td><td>44</td></tr>
      <tr><td><a href="https://huggingface.co/google/electra-base-discriminator" target="_blank" rel="noopener">google/electra-base-discriminator</a></td><td>58549625</td><td>66</td></tr>
      <tr><td><a href="https://huggingface.co/google-bert/bert-base-uncased" target="_blank" rel="noopener">google-bert/bert-base-uncased</a></td><td>53275807</td><td>2441</td></tr>
      <tr><td><a href="https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k" target="_blank" rel="noopener">timm/mobilenetv3_small_100.lamb_in1k</a></td><td>43762365</td><td>39</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-large" target="_blank" rel="noopener">FacebookAI/roberta-large</a></td><td>20426777</td><td>250</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" target="_blank" rel="noopener">sentence-transformers/all-mpnet-base-v2</a></td><td>17830892</td><td>1170</td></tr>
      <tr><td><a href="https://huggingface.co/openai/clip-vit-base-patch32" target="_blank" rel="noopener">openai/clip-vit-base-patch32</a></td><td>17638896</td><td>782</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/segmentation-3.0" target="_blank" rel="noopener">pyannote/segmentation-3.0</a></td><td>17234148</td><td>626</td></tr>
      <tr><td><a href="https://huggingface.co/tech4humans/yolov8s-signature-detector" target="_blank" rel="noopener">tech4humans/yolov8s-signature-detector</a></td><td>16874538</td><td>48</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM" target="_blank" rel="noopener">pyannote/wespeaker-voxceleb-resnet34-LM</a></td><td>14933122</td><td>80</td></tr>
      <tr><td><a href="https://huggingface.co/Bingsu/adetailer" target="_blank" rel="noopener">Bingsu/adetailer</a></td><td>14489181</td><td>620</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-base" target="_blank" rel="noopener">FacebookAI/roberta-base</a></td><td>14321545</td><td>529</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/speaker-diarization-3.1" target="_blank" rel="noopener">pyannote/speaker-diarization-3.1</a></td><td>14186095</td><td>1228</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>GitHub Trending Repositories</h2>
  <p class="metadata">Fetched at 2025-12-10T05:35:36Z • Source: <a href="https://api.github.com/search/repositories" target="_blank" rel="noopener">https://api.github.com/search/repositories</a> • Hash: <code>46d0817f88f92d1bb2b5b9275df2dc439e53538d8cb82f05f937c0c7e1003bc9</code></p>
  <table>
    <thead>
      <tr><th>Repository</th><th>Stars</th><th>Description</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://github.com/TakatoHonda/sui-lang" target="_blank" rel="noopener">TakatoHonda/sui-lang</a></td><td>234</td><td>粋 (Sui) - A programming language optimized for LLM code generation</td></tr>
      <tr><td><a href="https://github.com/DeNA/llm-study20251201" target="_blank" rel="noopener">DeNA/llm-study20251201</a></td><td>178</td><td>DeNA社内で実施したLLM勉強会の資料とソースコード</td></tr>
      <tr><td><a href="https://github.com/MedChaouch/Puzld.ai" target="_blank" rel="noopener">MedChaouch/Puzld.ai</a></td><td>132</td><td>Multi-LLM orchestration framework</td></tr>
      <tr><td><a href="https://github.com/dl1683/Latent-Space-Reasoning" target="_blank" rel="noopener">dl1683/Latent-Space-Reasoning</a></td><td>61</td><td>Teaching LLMs to reason in the Latent Space to precondition responses.</td></tr>
      <tr><td><a href="https://github.com/yen-shi-lun/Krita-Ollama-Prompt-Generator" target="_blank" rel="noopener">yen-shi-lun/Krita-Ollama-Prompt-Generator</a></td><td>35</td><td>Wuhe Design presents the Krita × Ollama Prompt Generator — a local LLM-powered plugin for generating, refining, and sending prompts directly into the krita-ai-…</td></tr>
      <tr><td><a href="https://github.com/kylehughes/the-unofficial-swift-concurrency-migration-skill" target="_blank" rel="noopener">kylehughes/the-unofficial-swift-concurrency-migration-skill</a></td><td>27</td><td>The Swift Concurrency Migration Guide, packaged as a Skill for LLMs.</td></tr>
      <tr><td><a href="https://github.com/yu-lin-li/DyToK" target="_blank" rel="noopener">yu-lin-li/DyToK</a></td><td>22</td><td>[NeurIPS 2025] Less Is More, but Where? Dynamic Token Compression via LLM-Guided Keyframe Prior</td></tr>
      <tr><td><a href="https://github.com/OpenMOSS/rope_pp" target="_blank" rel="noopener">OpenMOSS/rope_pp</a></td><td>19</td><td>Beyond Real: Imaginary Extension of Rotary Position Embeddings for Long-Context LLMs</td></tr>
      <tr><td><a href="https://github.com/kamath/questionnaire" target="_blank" rel="noopener">kamath/questionnaire</a></td><td>18</td><td>Ask users structured questions in an LLM chat! AI SDK + Shadcn</td></tr>
      <tr><td><a href="https://github.com/Glitch-Jar/LLM-EYES" target="_blank" rel="noopener">Glitch-Jar/LLM-EYES</a></td><td>15</td><td>Give LLMs eyes, then benchmark what they see</td></tr>
      <tr><td><a href="https://github.com/Chatit-cloud/BEE2BEE" target="_blank" rel="noopener">Chatit-cloud/BEE2BEE</a></td><td>12</td><td>Burgundy Bee | P2P protocol for Large Language Model</td></tr>
      <tr><td><a href="https://github.com/agynio/gh-pr-review" target="_blank" rel="noopener">agynio/gh-pr-review</a></td><td>12</td><td>GitHub CLI extension that adds full inline PR review comment support — view, navigate, reply to, and resolve review threads directly from the terminal. LLM-rea…</td></tr>
      <tr><td><a href="https://github.com/ynulihao/OpenRouterBench" target="_blank" rel="noopener">ynulihao/OpenRouterBench</a></td><td>11</td><td>OpenRouterBench: A One-Stop Benchmark and Solution Suite for LLM Routing</td></tr>
      <tr><td><a href="https://github.com/Rohitnegi9/STRIKEGenAI" target="_blank" rel="noopener">Rohitnegi9/STRIKEGenAI</a></td><td>9</td><td>This Is official documentation of Strike GenAI</td></tr>
      <tr><td><a href="https://github.com/eliteresearchlab/BRAINS" target="_blank" rel="noopener">eliteresearchlab/BRAINS</a></td><td>9</td><td>BRAINS is a production-ready, multi-agent medical diagnostic platform powered by Retrieval-Augmented Generation (RAG) and LLM inference. It combines a Next.js…</td></tr>
      <tr><td><a href="https://github.com/nextmoca/adl" target="_blank" rel="noopener">nextmoca/adl</a></td><td>8</td><td>ADL (Agent Definition Language) is a vendor-neutral, declarative standard for defining AI agents, including their tools, LLM settings, RAG inputs, permissions,…</td></tr>
      <tr><td><a href="https://github.com/shukunxiong/VRSA" target="_blank" rel="noopener">shukunxiong/VRSA</a></td><td>8</td><td>This is the code for Visual Reasoning Sequential Attack, which is a method to jailbreak Multimodal Large Language Models Based on their visual reasoning capabi…</td></tr>
      <tr><td><a href="https://github.com/Runtime-Exception/lmprobe" target="_blank" rel="noopener">Runtime-Exception/lmprobe</a></td><td>7</td><td>Probe multiple LLM API endpoints to detect available models, then serve them through a unified local API supporting both OpenAI and Anthropic Claude formats.</td></tr>
      <tr><td><a href="https://github.com/dangehub/obsidian-translay-translator" target="_blank" rel="noopener">dangehub/obsidian-translay-translator</a></td><td>7</td><td>调用你喜欢的AI（LLM）翻译Obsidian中的任何文本，支持词典导入导出</td></tr>
      <tr><td><a href="https://github.com/hannahjan06/MultiBrain-AI" target="_blank" rel="noopener">hannahjan06/MultiBrain-AI</a></td><td>7</td><td>MultiBrain AI is an automated meeting assistant that transcribes audio with Whisper, generates structured notes using an LLM, and automatically creates tasks,…</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Papers with Code</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z • Source: <a href="https://paperswithcode.com/api/v1/papers/" target="_blank" rel="noopener">https://paperswithcode.com/api/v1/papers/</a> • Hash: <code>d4a343f7408e936b9b783882d60713e7711a2e2104b924d1a9726c2b1660e60c</code></p>
  <p class="warning">Expecting value: line 1 column 1 (char 0)</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>Hacker News Highlights</h2>
  <p class="metadata">Fetched at 2025-12-10T05:35:36Z • Source: <a href="https://hacker-news.firebaseio.com/" target="_blank" rel="noopener">https://hacker-news.firebaseio.com/</a> • Hash: <code>61a9e5a1a0be49910be30e8324166438205a342cac6fea124f87c8eedb1a38f3</code></p>
  <table>
    <thead>
      <tr><th>Story</th><th>Score</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://news.ycombinator.com/item?id=46206457" target="_blank" rel="noopener">Ask HN: Should &quot;I asked $AI, and it said&quot; replies be forbidden in HN guidelines?</a></td><td>811</td><td>2025-12-09T16:02:37Z</td></tr>
      <tr><td><a href="https://finance.yahoo.com/news/apple-slow-ai-pace-becomes-104658095.html" target="_blank" rel="noopener">Apple&#x27;s slow AI pace becomes a strength as market grows weary of spending</a></td><td>282</td><td>2025-12-09T15:08:24Z</td></tr>
      <tr><td><a href="https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation" target="_blank" rel="noopener">Donating the Model Context Protocol and establishing the Agentic AI Foundation</a></td><td>182</td><td>2025-12-09T17:05:42Z</td></tr>
      <tr><td><a href="https://block.xyz/inside/block-anthropic-and-openai-launch-the-agentic-ai-foundation" target="_blank" rel="noopener">Agentic AI Foundation</a></td><td>88</td><td>2025-12-09T20:00:39Z</td></tr>
      <tr><td><a href="https://anandsanwal.me/ai-education-death-spiral/" target="_blank" rel="noopener">The AI-Education Death Spiral a.k.a. Let the Kids Cheat</a></td><td>51</td><td>2025-12-10T01:36:56Z</td></tr>
      <tr><td><a href="https://zenodo.org/records/17873275" target="_blank" rel="noopener">Post-transformer inference: 224× compression of Llama-70B with improved accuracy</a></td><td>43</td><td>2025-12-10T01:25:00Z</td></tr>
      <tr><td><a href="http://blog.modelcontextprotocol.io/posts/2025-12-09-mcp-joins-agentic-ai-foundation/" target="_blank" rel="noopener">MCP Joins the Agentic AI Foundation</a></td><td>28</td><td>2025-12-09T19:26:54Z</td></tr>
      <tr><td><a href="https://www.youtube.com/watch?v=osxr7xSxsGo" target="_blank" rel="noopener">Instacart uses AI to charge customers different prices for the same items [video]</a></td><td>26</td><td>2025-12-09T19:02:22Z</td></tr>
      <tr><td><a href="https://www.theverge.com/news/841219/google-gemini-us-military-ai-platform-genai-mil" target="_blank" rel="noopener">Google is powering a new US Military AI platform</a></td><td>26</td><td>2025-12-09T23:37:09Z</td></tr>
      <tr><td><a href="https://www.theatlantic.com/technology/2025/12/openai-losing-ai-wars/685201/" target="_blank" rel="noopener">OpenAI Is in Trouble</a></td><td>20</td><td>2025-12-09T23:10:34Z</td></tr>
      <tr><td><a href="https://sherwood.news/tech/ads-are-showing-up-on-googles-ai-mode-now/" target="_blank" rel="noopener">Ads are showing up on Google&#x27;s AI Mode now</a></td><td>16</td><td>2025-12-09T21:42:28Z</td></tr>
      <tr><td><a href="https://www.tomshardware.com/tech-industry/semiconductors/semiconductor-industry-enters-giga-cycle-as-ai-infrastructure-spending-reshapes-demand" target="_blank" rel="noopener">Semiconductor industry enters &#x27;giga cycle&#x27; – scale of AI is rewriting economics</a></td><td>15</td><td>2025-12-09T20:00:10Z</td></tr>
      <tr><td><a href="https://hivetechs.io" target="_blank" rel="noopener">Show HN: I got tired of switching AI tools, so I built an IDE with 11 of them</a></td><td>13</td><td>2025-12-09T14:49:51Z</td></tr>
      <tr><td><a href="https://www.theregister.com/2025/12/08/gartner_recommends_ai_browser_ban/" target="_blank" rel="noopener">Block all AI browsers for the foreseeable future: Gartner</a></td><td>11</td><td>2025-12-09T18:07:23Z</td></tr>
      <tr><td><a href="https://woe-industries.itch.io/you-have-billions-invested-in-generative-ai" target="_blank" rel="noopener">You Have Billions Invested in Generative AI</a></td><td>11</td><td>2025-12-10T02:28:04Z</td></tr>
      <tr><td><a href="https://medium.com/@gianlucabailo/building-a-modern-c64-assembly-ai-toolchain-using-google-gemini-3-1a36464c9458" target="_blank" rel="noopener">Building a Modern C64 Assembly AI Toolchain</a></td><td>9</td><td>2025-12-09T10:49:38Z</td></tr>
      <tr><td><a href="https://aaif.io/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation-aaif-anchored-by-new-project-contributions-including-model-context-protocol-mcp-goose-and-agents-md/" target="_blank" rel="noopener">Linux Foundation Announces the Formation of the Agentic AI Foundation</a></td><td>7</td><td>2025-12-09T20:47:55Z</td></tr>
      <tr><td><a href="https://twitter.com/xai/status/1997875236415676619" target="_blank" rel="noopener">Halftime: Dynamically weaves AI-generated ads into the scenes you&#x27;re watching</a></td><td>6</td><td>2025-12-10T00:20:45Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Latest CVEs</h2>
  <p class="metadata">Fetched at 2025-12-10T05:35:36Z • Source: <a href="https://cve.circl.lu/api/last" target="_blank" rel="noopener">https://cve.circl.lu/api/last</a> • Hash: <code>e219945875b63e761e392e6da1ed6f78ac38d17453256e099f8684c112569578</code></p>
  <table>
    <thead>
      <tr><th>CVE</th><th>CVSS</th><th>Summary</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-6263" target="_blank" rel="noopener">MAL-2025-6263</a></td><td>0.0</td><td>Malicious code in package-with-conditions (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-192345" target="_blank" rel="noopener">MAL-2025-192345</a></td><td>0.0</td><td>Malicious code in native-component-list (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-192346" target="_blank" rel="noopener">MAL-2025-192346</a></td><td>0.0</td><td>Malicious code in non-modular-buildable (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-192421" target="_blank" rel="noopener">MAL-2025-192421</a></td><td>0.0</td><td>Malicious code in vue2-amis-custom-widget123 (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-192420" target="_blank" rel="noopener">MAL-2025-192420</a></td><td>0.0</td><td>Malicious code in near-fast-auth-signer (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-192423" target="_blank" rel="noopener">MAL-2025-192423</a></td><td>0.0</td><td>Malicious code in vue2-amis-custom-widget-pro (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-13677" target="_blank" rel="noopener">CVE-2025-13677</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-67605" target="_blank" rel="noopener">CVE-2025-67605</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-67606" target="_blank" rel="noopener">CVE-2025-67606</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=CVE-2025-67607" target="_blank" rel="noopener">CVE-2025-67607</a></td><td>0.0</td><td></td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Datasets</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z • Source: <a href="https://huggingface.co/api/datasets" target="_blank" rel="noopener">https://huggingface.co/api/datasets</a> • Hash: <code>4b4cc33871c4b3cd497c500155aa79f37885aa24df2d895e1d18c0c80ab6ae9c</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Dataset</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/datasets/nebius/SWE-rebench" target="_blank" rel="noopener">nebius/SWE-rebench</a></td><td>3717252</td><td>35</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/SWE-Gym/SWE-Gym" target="_blank" rel="noopener">SWE-Gym/SWE-Gym</a></td><td>2041687</td><td>20</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/huggingface/documentation-images" target="_blank" rel="noopener">huggingface/documentation-images</a></td><td>2014781</td><td>86</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/chcorbi/helvipad" target="_blank" rel="noopener">chcorbi/helvipad</a></td><td>1478443</td><td>10</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/AquaV/genshin-voices-separated" target="_blank" rel="noopener">AquaV/genshin-voices-separated</a></td><td>1461805</td><td>8</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/banned-historical-archives/banned-historical-archives" target="_blank" rel="noopener">banned-historical-archives/banned-historical-archives</a></td><td>1411450</td><td>5</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim" target="_blank" rel="noopener">nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim</a></td><td>1339503</td><td>155</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/princeton-nlp/SWE-bench_Verified" target="_blank" rel="noopener">princeton-nlp/SWE-bench_Verified</a></td><td>1282494</td><td>218</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/lavita/medical-qa-shared-task-v1-toy" target="_blank" rel="noopener">lavita/medical-qa-shared-task-v1-toy</a></td><td>878541</td><td>21</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/Salesforce/wikitext" target="_blank" rel="noopener">Salesforce/wikitext</a></td><td>867174</td><td>505</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/language_table_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/language_table_lerobot</a></td><td>786287</td><td>0</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/droid_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/droid_lerobot</a></td><td>737114</td><td>6</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/hf-doc-build/doc-build" target="_blank" rel="noopener">hf-doc-build/doc-build</a></td><td>671848</td><td>12</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/applied-ai-018/pretraining_v1-omega_books" target="_blank" rel="noopener">applied-ai-018/pretraining_v1-omega_books</a></td><td>614296</td><td>2</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu" target="_blank" rel="noopener">HuggingFaceFW/fineweb-edu</a></td><td>597646</td><td>775</td></tr>
    </tbody>
  </table>
</section>
  </main>
  <footer><p>Datasets updated as part of the DeepTech Daily automation run.</p><p>Last refreshed at 2025-12-10T05:35:36Z.</p><ul><li><a href="../deeptech-daily/data/gpu_prices.json">gpu_prices.json</a></li><li><a href="../deeptech-daily/data/arxiv.yaml">arxiv.yaml</a></li><li><a href="../deeptech-daily/data/hf_trending.yaml">hf_trending.yaml</a></li><li><a href="../deeptech-daily/data/github_trending.yaml">github_trending.yaml</a></li><li><a href="../deeptech-daily/data/pwc_llm.yaml">pwc_llm.yaml</a></li><li><a href="../deeptech-daily/data/hn_ai.yaml">hn_ai.yaml</a></li><li><a href="../deeptech-daily/data/cves.yaml">cves.yaml</a></li><li><a href="../deeptech-daily/data/hf_datasets.yaml">hf_datasets.yaml</a></li></ul></footer>
</body>
</html>
