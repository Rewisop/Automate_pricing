<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>DeepTech Daily Dashboard</title>
  <style>
body { font-family: 'Inter', 'Segoe UI', system-ui, -apple-system, sans-serif; margin: 0; padding: 0; background: #0f172a; color: #e2e8f0; }
header { padding: 2.5rem 1.5rem; text-align: center; background: #1e293b; }
header h1 { margin: 0 0 0.5rem; font-size: 2.5rem; }
header p { margin: 0; color: #94a3b8; font-size: 1rem; }
main { max-width: 1100px; margin: 0 auto; padding: 2rem 1.5rem 4rem; }
section { background: rgba(15, 23, 42, 0.75); border: 1px solid rgba(148, 163, 184, 0.2); border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 12px 24px rgba(15, 23, 42, 0.4); }
section h2 { margin-top: 0; color: #f8fafc; font-size: 1.5rem; }
table { width: 100%; border-collapse: collapse; margin-top: 1rem; }
th, td { text-align: left; padding: 0.65rem 0.75rem; border-bottom: 1px solid rgba(148, 163, 184, 0.2); }
th { background: rgba(148, 163, 184, 0.1); color: #e2e8f0; font-weight: 600; }
tr:hover td { background: rgba(59, 130, 246, 0.08); }
a { color: #38bdf8; text-decoration: none; }
a:hover { text-decoration: underline; }
.warning { margin: 0.75rem 0; color: #fbbf24; }
.empty { margin: 1rem 0 0; color: #94a3b8; font-style: italic; }
.metadata { margin: 0.35rem 0 0; color: #94a3b8; font-size: 0.9rem; }
footer { text-align: center; padding: 2rem 1.5rem 3rem; color: #64748b; font-size: 0.9rem; }
footer ul { list-style: none; padding: 0; margin: 1rem 0 0; display: flex; flex-wrap: wrap; gap: 0.75rem; justify-content: center; }
footer li { background: rgba(148, 163, 184, 0.1); border-radius: 6px; padding: 0.4rem 0.75rem; }
</style>
</head>
<body>
  <header>
    <h1>DeepTech Daily Dashboard</h1>
    <p>A curated snapshot of GPUs, research, software, and security intel powered by the DeepTech Daily datasets.</p>
  </header>
  <main>
    <section>
  <h2>GPU Pricing Snapshot</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z • Source: <a href="https://vast.ai/api/v0/bundles/public" target="_blank" rel="noopener">https://vast.ai/api/v0/bundles/public</a>, <a href="https://api.runpod.io" target="_blank" rel="noopener">https://api.runpod.io</a>, <a href="https://modal.com/api" target="_blank" rel="noopener">https://modal.com/api</a> • Hash: <code>73cd0d24819c38ed4bb8d48de66e8dd1013b8b60870640a96bc6c90d3b6d6974</code></p>
  <p class="warning">Vast.ai: 404 Client Error: Not Found for url: https://console.vast.ai/api/v0/bundles/public/?limit=200&amp;skip=0</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>arXiv Digest</h2>
  <p class="metadata">Fetched at 2025-11-24T05:34:43Z • Source: <a href="https://export.arxiv.org/rss/cs.AI" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.AI</a>, <a href="https://export.arxiv.org/rss/cs.CL" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.CL</a>, <a href="https://export.arxiv.org/rss/cs.LG" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.LG</a> • Hash: <code>24d0c69d61bd9492788e9f83db120f49e8f1155fcca0a4d5a93c044dfc123849</code></p>
  <table>
    <thead>
      <tr><th>Title</th><th>Summary</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://arxiv.org/abs/2511.16814" target="_blank" rel="noopener">Stable diffusion models reveal a persisting human and AI gap in visual creativity</a></td><td>arXiv:2511.16814v1 Announce Type: new  Abstract: While recent research suggests Large Language Models match human creative performance in divergent thinking ta…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.16837" target="_blank" rel="noopener">Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs</a></td><td>arXiv:2511.16837v1 Announce Type: new  Abstract: Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large la…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.16842" target="_blank" rel="noopener">Fantastic Bugs and Where to Find Them in AI Benchmarks</a></td><td>arXiv:2511.16842v1 Announce Type: new  Abstract: Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reli…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.16916" target="_blank" rel="noopener">Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving</a></td><td>arXiv:2511.16916v1 Announce Type: new  Abstract: In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-base…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.16961" target="_blank" rel="noopener">Comparing verbal, visual and combined explanations for Bayesian Network inferences</a></td><td>arXiv:2511.16961v1 Announce Type: new  Abstract: Bayesian Networks (BNs) are an important tool for assisting probabilistic reasoning, but despite being conside…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.16997" target="_blank" rel="noopener">MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists</a></td><td>arXiv:2511.16997v1 Announce Type: new  Abstract: The emergence of AI Scientists has demonstrated remarkable potential in automating scientific research. Howeve…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.17006" target="_blank" rel="noopener">Budget-Aware Tool-Use Enables Effective Agent Scaling</a></td><td>arXiv:2511.17006v1 Announce Type: new  Abstract: Scaling test-time computation improves performance across different tasks on large language models (LLMs), whi…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.17038" target="_blank" rel="noopener">DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing</a></td><td>arXiv:2511.17038v1 Announce Type: new  Abstract: From a Bayesian perspective, score-based diffusion solves inverse problems through joint inference, embedding…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.17056" target="_blank" rel="noopener">Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks</a></td><td>arXiv:2511.17056v1 Announce Type: new  Abstract: Electronic health records (EHRs) form an invaluable resource for training clinical decision support systems. T…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.17162" target="_blank" rel="noopener">The Belief-Desire-Intention Ontology for modelling mental reality and agency</a></td><td>arXiv:2511.17162v1 Announce Type: new  Abstract: The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intell…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.17165" target="_blank" rel="noopener">MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward</a></td><td>arXiv:2511.17165v1 Announce Type: new  Abstract: Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods hav…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.17198" target="_blank" rel="noopener">Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism</a></td><td>arXiv:2511.17198v1 Announce Type: new  Abstract: LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, ofte…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.17332" target="_blank" rel="noopener">Agentifying Agentic AI</a></td><td>arXiv:2511.17332v1 Announce Type: new  Abstract: Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.17408" target="_blank" rel="noopener">That&#x27;s not natural: The Impact of Off-Policy Training Data on Probe Performance</a></td><td>arXiv:2511.17408v1 Announce Type: new  Abstract: Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time…</td><td>2025-11-24T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.17461" target="_blank" rel="noopener">SRA-CP: Spontaneous Risk-Aware Selective Cooperative Perception</a></td><td>arXiv:2511.17461v1 Announce Type: new  Abstract: Cooperative perception (CP) offers significant potential to overcome the limitations of single-vehicle sensing…</td><td>2025-11-24T05:00:00Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Models</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z • Source: <a href="https://huggingface.co/api/models" target="_blank" rel="noopener">https://huggingface.co/api/models</a> • Hash: <code>edb3d86947c5f8d876d9c4481cb4419a0d2e7876af7b8f691870930c02d571fc</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Model</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/Falconsai/nsfw_image_detection" target="_blank" rel="noopener">Falconsai/nsfw_image_detection</a></td><td>122866637</td><td>847</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" target="_blank" rel="noopener">sentence-transformers/all-MiniLM-L6-v2</a></td><td>118061338</td><td>4004</td></tr>
      <tr><td><a href="https://huggingface.co/dima806/fairface_age_image_detection" target="_blank" rel="noopener">dima806/fairface_age_image_detection</a></td><td>81641974</td><td>44</td></tr>
      <tr><td><a href="https://huggingface.co/google/electra-base-discriminator" target="_blank" rel="noopener">google/electra-base-discriminator</a></td><td>58549625</td><td>66</td></tr>
      <tr><td><a href="https://huggingface.co/google-bert/bert-base-uncased" target="_blank" rel="noopener">google-bert/bert-base-uncased</a></td><td>53275807</td><td>2441</td></tr>
      <tr><td><a href="https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k" target="_blank" rel="noopener">timm/mobilenetv3_small_100.lamb_in1k</a></td><td>43762365</td><td>39</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-large" target="_blank" rel="noopener">FacebookAI/roberta-large</a></td><td>20426777</td><td>250</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" target="_blank" rel="noopener">sentence-transformers/all-mpnet-base-v2</a></td><td>17830892</td><td>1170</td></tr>
      <tr><td><a href="https://huggingface.co/openai/clip-vit-base-patch32" target="_blank" rel="noopener">openai/clip-vit-base-patch32</a></td><td>17638896</td><td>782</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/segmentation-3.0" target="_blank" rel="noopener">pyannote/segmentation-3.0</a></td><td>17234148</td><td>626</td></tr>
      <tr><td><a href="https://huggingface.co/tech4humans/yolov8s-signature-detector" target="_blank" rel="noopener">tech4humans/yolov8s-signature-detector</a></td><td>16874538</td><td>48</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM" target="_blank" rel="noopener">pyannote/wespeaker-voxceleb-resnet34-LM</a></td><td>14933122</td><td>80</td></tr>
      <tr><td><a href="https://huggingface.co/Bingsu/adetailer" target="_blank" rel="noopener">Bingsu/adetailer</a></td><td>14489181</td><td>620</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-base" target="_blank" rel="noopener">FacebookAI/roberta-base</a></td><td>14321545</td><td>529</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/speaker-diarization-3.1" target="_blank" rel="noopener">pyannote/speaker-diarization-3.1</a></td><td>14186095</td><td>1228</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>GitHub Trending Repositories</h2>
  <p class="metadata">Fetched at 2025-11-24T05:34:43Z • Source: <a href="https://api.github.com/search/repositories" target="_blank" rel="noopener">https://api.github.com/search/repositories</a> • Hash: <code>9377dce0923070500481763711f7712b6425825f13762b987cd30d281a547041</code></p>
  <table>
    <thead>
      <tr><th>Repository</th><th>Stars</th><th>Description</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://github.com/karpathy/llm-council" target="_blank" rel="noopener">karpathy/llm-council</a></td><td>2732</td><td>LLM Council works together to answer your hardest questions</td></tr>
      <tr><td><a href="https://github.com/karpathy/reader3" target="_blank" rel="noopener">karpathy/reader3</a></td><td>2004</td><td>Quick illustration of how one can easily read books together with LLMs. It&#x27;s great and I highly recommend it.</td></tr>
      <tr><td><a href="https://github.com/mega002/llm-interp-tau" target="_blank" rel="noopener">mega002/llm-interp-tau</a></td><td>157</td><td>Course Materials for Interpretability of Large Language Models (0368.4264) at Tel Aviv University</td></tr>
      <tr><td><a href="https://github.com/asker-kurtelli/scroll" target="_blank" rel="noopener">asker-kurtelli/scroll</a></td><td>96</td><td>chrome extension for better LLM chat navigation</td></tr>
      <tr><td><a href="https://github.com/Vyntral/god-eye" target="_blank" rel="noopener">Vyntral/god-eye</a></td><td>95</td><td>AI-powered subdomain enumeration tool with local LLM analysis via Ollama - 100% private, zero API costs</td></tr>
      <tr><td><a href="https://github.com/mouna23/OSINT-with-LLM" target="_blank" rel="noopener">mouna23/OSINT-with-LLM</a></td><td>44</td><td>It’s an OSINT reconnaissance poc powered by Local LLMs (Ollama). You can feed it an email, domain, or IP, and it automatically performs multiple types of recon…</td></tr>
      <tr><td><a href="https://github.com/BeRo1985/pasllm" target="_blank" rel="noopener">BeRo1985/pasllm</a></td><td>43</td><td>PasLLM - LLM inference engine in Object Pascal (synced from my private work repository)</td></tr>
      <tr><td><a href="https://github.com/messkan/prompt-cache" target="_blank" rel="noopener">messkan/prompt-cache</a></td><td>24</td><td>Cut LLM costs by up to 80% and unlock sub-millisecond responses with intelligent semantic caching. A drop-in OpenAI-compatible proxy written in Go.</td></tr>
      <tr><td><a href="https://github.com/KD-TAO/OmniZip" target="_blank" rel="noopener">KD-TAO/OmniZip</a></td><td>23</td><td>OmniZip: Audio-Guided Dynamic Token Compression for Fast Omnimodal Large Language Models</td></tr>
      <tr><td><a href="https://github.com/Siyou-Li/QTSplus" target="_blank" rel="noopener">Siyou-Li/QTSplus</a></td><td>13</td><td>Query-aware Token Selector (QTSplus), a lightweight yet powerful visual token selection module that serves as an information gate between the vision encoder an…</td></tr>
      <tr><td><a href="https://github.com/kylehughes/the-unofficial-swift-programming-language-skill" target="_blank" rel="noopener">kylehughes/the-unofficial-swift-programming-language-skill</a></td><td>12</td><td>The Swift Programming Language, packaged as a Skill for LLMs.</td></tr>
      <tr><td><a href="https://github.com/Dr-AneeshJoseph/Claude-Metacognitive-Skills" target="_blank" rel="noopener">Dr-AneeshJoseph/Claude-Metacognitive-Skills</a></td><td>11</td><td>Various research skill packages to explore LLM Metacognition, mainly Claude AI including substrate access and texture discrimination</td></tr>
      <tr><td><a href="https://github.com/davidesantangelo/cton" target="_blank" rel="noopener">davidesantangelo/cton</a></td><td>11</td><td>CTON provides a JSON-compatible, token-efficient text representation optimized for LLM prompts.</td></tr>
      <tr><td><a href="https://github.com/uwejan/tokio-actors" target="_blank" rel="noopener">uwejan/tokio-actors</a></td><td>10</td><td>Zero-ceremony, Tokio-native actors with strong typing and production-ready edge case handling, perfect for AI/LLM Applications.</td></tr>
      <tr><td><a href="https://github.com/jahnavik186/AI-Mental-Health-Companion" target="_blank" rel="noopener">jahnavik186/AI-Mental-Health-Companion</a></td><td>9</td><td>An intelligent, interactive mental health companion that uses Large Language Models (LLMs) combined with RAG to provide context-aware mental wellness guidance,…</td></tr>
      <tr><td><a href="https://github.com/jesbnc100/celarium" target="_blank" rel="noopener">jesbnc100/celarium</a></td><td>8</td><td>Privacy middleware for multi-agent LLM systems</td></tr>
      <tr><td><a href="https://github.com/mouna23/AI-driven-MITRE-Attack" target="_blank" rel="noopener">mouna23/AI-driven-MITRE-Attack</a></td><td>8</td><td>This repository demonstrates a machine learning pipeline for detecting MITRE ATT&amp;CK techniques from logs and enriching the output using a local LLM.</td></tr>
      <tr><td><a href="https://github.com/OpenCausaLab/DEPO" target="_blank" rel="noopener">OpenCausaLab/DEPO</a></td><td>7</td><td>[AAAI 2026] Code and Data for Paper &quot;DEPO: Dual-Efficiency Preference Optimization for LLM Agents&quot;</td></tr>
      <tr><td><a href="https://github.com/R44VC0RP/gitcom.dev" target="_blank" rel="noopener">R44VC0RP/gitcom.dev</a></td><td>7</td><td>Gitcom -&gt; LLM ready Github PR comments in markdown.</td></tr>
      <tr><td><a href="https://github.com/XXXDoriXXX/RepoToPrompt" target="_blank" rel="noopener">XXXDoriXXX/RepoToPrompt</a></td><td>6</td><td>Turns your local codebase into a secure, token-optimized context prompt for LLMs like ChatGPT and Claude.</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Papers with Code</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z • Source: <a href="https://paperswithcode.com/api/v1/papers/" target="_blank" rel="noopener">https://paperswithcode.com/api/v1/papers/</a> • Hash: <code>d4a343f7408e936b9b783882d60713e7711a2e2104b924d1a9726c2b1660e60c</code></p>
  <p class="warning">Expecting value: line 1 column 1 (char 0)</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>Hacker News Highlights</h2>
  <p class="metadata">Fetched at 2025-11-24T05:34:43Z • Source: <a href="https://hacker-news.firebaseio.com/" target="_blank" rel="noopener">https://hacker-news.firebaseio.com/</a> • Hash: <code>5388a5966a6ef605b6700bfc86cc855e464112270ce46dca3d730c83b089da1d</code></p>
  <table>
    <thead>
      <tr><th>Story</th><th>Score</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://www.theguardian.com/technology/2025/nov/22/ai-workers-tell-family-stay-away" target="_blank" rel="noopener">Meet the AI workers who tell their friends and family to stay away from AI</a></td><td>50</td><td>2025-11-23T21:01:26Z</td></tr>
      <tr><td><a href="https://www.npmjs.com/package/tosijs-schema" target="_blank" rel="noopener">Tosijs-schema is a super lightweight schema-first LLM-native JSON schema library</a></td><td>43</td><td>2025-11-23T13:43:24Z</td></tr>
      <tr><td><a href="https://arstechnica.com/science/2025/11/generative-ai-meets-the-genome/" target="_blank" rel="noopener">AI trained on bacterial genomes produces never-before-seen proteins</a></td><td>18</td><td>2025-11-23T19:05:22Z</td></tr>
      <tr><td><a href="https://thenewstack.io/is-ai-creating-a-new-code-review-bottleneck-for-senior-engineers/" target="_blank" rel="noopener">&#x27;Is AI creating a new code review bottleneck for senior engineers?&#x27;</a></td><td>16</td><td>2025-11-23T16:43:59Z</td></tr>
      <tr><td><a href="https://www.ft.com/content/abfe9741-f438-4ed6-a673-075ec177dc62" target="_blank" rel="noopener">Insurers retreat from AI cover as risk of multibillion-dollar claims mounts</a></td><td>13</td><td>2025-11-24T04:22:12Z</td></tr>
      <tr><td><a href="https://huggingface.co/spaces/Supertone/supertonic" target="_blank" rel="noopener">Supertonic: Ultra-lightweight on-device TTS model open source by Supertone</a></td><td>10</td><td>2025-11-23T23:54:58Z</td></tr>
      <tr><td><a href="https://www.dank-ai.xyz/" target="_blank" rel="noopener">Show HN: Dank-AI – Ship production AI agents 10x faster</a></td><td>6</td><td>2025-11-23T05:54:32Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Latest CVEs</h2>
  <p class="metadata">Fetched at 2025-11-24T05:34:43Z • Source: <a href="https://cve.circl.lu/api/last" target="_blank" rel="noopener">https://cve.circl.lu/api/last</a> • Hash: <code>e0c55fe23528304194678c5a08cb0fd3a3949f319c554d40e9d695e3a606c3f4</code></p>
  <table>
    <thead>
      <tr><th>CVE</th><th>CVSS</th><th>Summary</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-190623" target="_blank" rel="noopener">MAL-2025-190623</a></td><td>0.0</td><td>Malicious code in cbre-flow-common (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-190624" target="_blank" rel="noopener">MAL-2025-190624</a></td><td>0.0</td><td>Malicious code in base62-58x (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-190625" target="_blank" rel="noopener">MAL-2025-190625</a></td><td>0.0</td><td>Malicious code in lion-second-package (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-g62q-chj4-h9wq" target="_blank" rel="noopener">GHSA-g62q-chj4-h9wq</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-m83v-rwh2-8cwf" target="_blank" rel="noopener">GHSA-m83v-rwh2-8cwf</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-q2cr-96j4-c73w" target="_blank" rel="noopener">GHSA-q2cr-96j4-c73w</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-vcmm-whq7-r33v" target="_blank" rel="noopener">GHSA-vcmm-whq7-r33v</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-9966-qw6r-4xwx" target="_blank" rel="noopener">GHSA-9966-qw6r-4xwx</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=GHSA-rwcf-q33h-h6vh" target="_blank" rel="noopener">GHSA-rwcf-q33h-h6vh</a></td><td>0.0</td><td></td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-190626" target="_blank" rel="noopener">MAL-2025-190626</a></td><td>0.0</td><td>Malicious code in vue3-transpiler (npm)</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Datasets</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z • Source: <a href="https://huggingface.co/api/datasets" target="_blank" rel="noopener">https://huggingface.co/api/datasets</a> • Hash: <code>4b4cc33871c4b3cd497c500155aa79f37885aa24df2d895e1d18c0c80ab6ae9c</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Dataset</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/datasets/nebius/SWE-rebench" target="_blank" rel="noopener">nebius/SWE-rebench</a></td><td>3717252</td><td>35</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/SWE-Gym/SWE-Gym" target="_blank" rel="noopener">SWE-Gym/SWE-Gym</a></td><td>2041687</td><td>20</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/huggingface/documentation-images" target="_blank" rel="noopener">huggingface/documentation-images</a></td><td>2014781</td><td>86</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/chcorbi/helvipad" target="_blank" rel="noopener">chcorbi/helvipad</a></td><td>1478443</td><td>10</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/AquaV/genshin-voices-separated" target="_blank" rel="noopener">AquaV/genshin-voices-separated</a></td><td>1461805</td><td>8</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/banned-historical-archives/banned-historical-archives" target="_blank" rel="noopener">banned-historical-archives/banned-historical-archives</a></td><td>1411450</td><td>5</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim" target="_blank" rel="noopener">nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim</a></td><td>1339503</td><td>155</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/princeton-nlp/SWE-bench_Verified" target="_blank" rel="noopener">princeton-nlp/SWE-bench_Verified</a></td><td>1282494</td><td>218</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/lavita/medical-qa-shared-task-v1-toy" target="_blank" rel="noopener">lavita/medical-qa-shared-task-v1-toy</a></td><td>878541</td><td>21</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/Salesforce/wikitext" target="_blank" rel="noopener">Salesforce/wikitext</a></td><td>867174</td><td>505</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/language_table_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/language_table_lerobot</a></td><td>786287</td><td>0</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/droid_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/droid_lerobot</a></td><td>737114</td><td>6</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/hf-doc-build/doc-build" target="_blank" rel="noopener">hf-doc-build/doc-build</a></td><td>671848</td><td>12</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/applied-ai-018/pretraining_v1-omega_books" target="_blank" rel="noopener">applied-ai-018/pretraining_v1-omega_books</a></td><td>614296</td><td>2</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu" target="_blank" rel="noopener">HuggingFaceFW/fineweb-edu</a></td><td>597646</td><td>775</td></tr>
    </tbody>
  </table>
</section>
  </main>
  <footer><p>Datasets updated as part of the DeepTech Daily automation run.</p><p>Last refreshed at 2025-11-24T05:34:43Z.</p><ul><li><a href="../deeptech-daily/data/gpu_prices.json">gpu_prices.json</a></li><li><a href="../deeptech-daily/data/arxiv.yaml">arxiv.yaml</a></li><li><a href="../deeptech-daily/data/hf_trending.yaml">hf_trending.yaml</a></li><li><a href="../deeptech-daily/data/github_trending.yaml">github_trending.yaml</a></li><li><a href="../deeptech-daily/data/pwc_llm.yaml">pwc_llm.yaml</a></li><li><a href="../deeptech-daily/data/hn_ai.yaml">hn_ai.yaml</a></li><li><a href="../deeptech-daily/data/cves.yaml">cves.yaml</a></li><li><a href="../deeptech-daily/data/hf_datasets.yaml">hf_datasets.yaml</a></li></ul></footer>
</body>
</html>
