<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>DeepTech Daily Dashboard</title>
  <style>
body { font-family: 'Inter', 'Segoe UI', system-ui, -apple-system, sans-serif; margin: 0; padding: 0; background: #0f172a; color: #e2e8f0; }
header { padding: 2.5rem 1.5rem; text-align: center; background: #1e293b; }
header h1 { margin: 0 0 0.5rem; font-size: 2.5rem; }
header p { margin: 0; color: #94a3b8; font-size: 1rem; }
main { max-width: 1100px; margin: 0 auto; padding: 2rem 1.5rem 4rem; }
section { background: rgba(15, 23, 42, 0.75); border: 1px solid rgba(148, 163, 184, 0.2); border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 12px 24px rgba(15, 23, 42, 0.4); }
section h2 { margin-top: 0; color: #f8fafc; font-size: 1.5rem; }
table { width: 100%; border-collapse: collapse; margin-top: 1rem; }
th, td { text-align: left; padding: 0.65rem 0.75rem; border-bottom: 1px solid rgba(148, 163, 184, 0.2); }
th { background: rgba(148, 163, 184, 0.1); color: #e2e8f0; font-weight: 600; }
tr:hover td { background: rgba(59, 130, 246, 0.08); }
a { color: #38bdf8; text-decoration: none; }
a:hover { text-decoration: underline; }
.warning { margin: 0.75rem 0; color: #fbbf24; }
.empty { margin: 1rem 0 0; color: #94a3b8; font-style: italic; }
.metadata { margin: 0.35rem 0 0; color: #94a3b8; font-size: 0.9rem; }
footer { text-align: center; padding: 2rem 1.5rem 3rem; color: #64748b; font-size: 0.9rem; }
footer ul { list-style: none; padding: 0; margin: 1rem 0 0; display: flex; flex-wrap: wrap; gap: 0.75rem; justify-content: center; }
footer li { background: rgba(148, 163, 184, 0.1); border-radius: 6px; padding: 0.4rem 0.75rem; }
</style>
</head>
<body>
  <header>
    <h1>DeepTech Daily Dashboard</h1>
    <p>A curated snapshot of GPUs, research, software, and security intel powered by the DeepTech Daily datasets.</p>
  </header>
  <main>
    <section>
  <h2>GPU Pricing Snapshot</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z • Source: <a href="https://vast.ai/api/v0/bundles/public" target="_blank" rel="noopener">https://vast.ai/api/v0/bundles/public</a>, <a href="https://api.runpod.io" target="_blank" rel="noopener">https://api.runpod.io</a>, <a href="https://modal.com/api" target="_blank" rel="noopener">https://modal.com/api</a> • Hash: <code>73cd0d24819c38ed4bb8d48de66e8dd1013b8b60870640a96bc6c90d3b6d6974</code></p>
  <p class="warning">Vast.ai: 404 Client Error: Not Found for url: https://console.vast.ai/api/v0/bundles/public/?limit=200&amp;skip=0</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>arXiv Digest</h2>
  <p class="metadata">Fetched at 2025-12-01T05:43:03Z • Source: <a href="https://export.arxiv.org/rss/cs.AI" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.AI</a>, <a href="https://export.arxiv.org/rss/cs.CL" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.CL</a>, <a href="https://export.arxiv.org/rss/cs.LG" target="_blank" rel="noopener">https://export.arxiv.org/rss/cs.LG</a> • Hash: <code>4c1404bd392e86929ee96ead21940cb65353e501f4f99136a4ef9000d6426c36</code></p>
  <table>
    <thead>
      <tr><th>Title</th><th>Summary</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://arxiv.org/abs/2511.21779" target="_blank" rel="noopener">Aligning Artificial Superintelligence via a Multi-Box Protocol</a></td><td>arXiv:2511.21779v1 Announce Type: new  Abstract: We propose a novel protocol for aligning artificial superintelligence (ASI) based on mutual verification among…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.21827" target="_blank" rel="noopener">Evaluating Strategies for Synthesizing Clinical Notes for Medical Multimodal AI</a></td><td>arXiv:2511.21827v1 Announce Type: new  Abstract: Multimodal (MM) learning is emerging as a promising paradigm in biomedical artificial intelligence (AI) applic…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22033" target="_blank" rel="noopener">Pathology-Aware Prototype Evolution via LLM-Driven Semantic Disambiguation for Multicenter Diabetic Retinopathy Diagnosis</a></td><td>arXiv:2511.22033v1 Announce Type: new  Abstract: Diabetic retinopathy (DR) grading plays a critical role in early clinical intervention and vision preservation…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22074" target="_blank" rel="noopener">Real-Time Procedural Learning From Experience for AI Agents</a></td><td>arXiv:2511.22074v1 Announce Type: new  Abstract: Learning how to do things from trial and error in real time is a hallmark of biological intelligence, yet most…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22076" target="_blank" rel="noopener">Hybrid Stackelberg Game and Diffusion-based Auction for Two-tier Agentic AI Task Offloading in Internet of Agents</a></td><td>arXiv:2511.22076v1 Announce Type: new  Abstract: The Internet of Agents (IoA) is rapidly gaining prominence as a foundational architecture for interconnected i…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22151" target="_blank" rel="noopener">A perceptual bias of AI Logical Argumentation Ability in Writing</a></td><td>arXiv:2511.22151v1 Announce Type: new  Abstract: Can machines think? This is a central question in artificial intelligence research. However, there is a substa…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22154" target="_blank" rel="noopener">WearVQA: A Visual Question Answering Benchmark for Wearables in Egocentric Authentic Real-world scenarios</a></td><td>arXiv:2511.22154v1 Announce Type: new  Abstract: We introduce WearVQA, the first benchmark specifically designed to evaluate the Visual Question Answering (VQA…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22226" target="_blank" rel="noopener">Embedded Universal Predictive Intelligence: a coherent framework for multi-agent learning</a></td><td>arXiv:2511.22226v1 Announce Type: new  Abstract: The standard theory of model-free reinforcement learning assumes that the environment dynamics are stationary…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22235" target="_blank" rel="noopener">Training High-Level Schedulers with Execution-Feedback Reinforcement Learning for Long-Horizon GUI Automation</a></td><td>arXiv:2511.22235v1 Announce Type: new  Abstract: The rapid development of large vision-language model (VLM) has greatly promoted the research of GUI agent. How…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22254" target="_blank" rel="noopener">Co-Evolving Agents: Learning from Failures as Hard Negatives</a></td><td>arXiv:2511.22254v1 Announce Type: new  Abstract: The rapid progress of large foundation models has accelerated the development of task-specialized agents acros…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22275" target="_blank" rel="noopener">RecToM: A Benchmark for Evaluating Machine Theory of Mind in LLM-based Conversational Recommender Systems</a></td><td>arXiv:2511.22275v1 Announce Type: new  Abstract: Large Language models are revolutionizing the conversational recommender systems through their impressive capa…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22302" target="_blank" rel="noopener">When AI Bends Metal: AI-Assisted Optimization of Design Parameters in Sheet Metal Forming</a></td><td>arXiv:2511.22302v1 Announce Type: new  Abstract: Numerical simulations have revolutionized the industrial design process by reducing prototyping costs, design…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22307" target="_blank" rel="noopener">Enhanced Conditional Generation of Double Perovskite by Knowledge-Guided Language Model Feedback</a></td><td>arXiv:2511.22307v1 Announce Type: new  Abstract: Double perovskites (DPs) are promising candidates for sustainable energy technologies due to their composition…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22311" target="_blank" rel="noopener">Swarms of Large Language Model Agents for Protein Sequence Design with Experimental Validation</a></td><td>arXiv:2511.22311v1 Announce Type: new  Abstract: Designing proteins de novo with tailored structural, physicochemical, and functional properties remains a gran…</td><td>2025-12-01T05:00:00Z</td></tr>
      <tr><td><a href="https://arxiv.org/abs/2511.22325" target="_blank" rel="noopener">Tracing Footsteps of Similar Cities: Modeling Urban Economic Vitality with Dynamic Inter-City Graph Embeddings</a></td><td>arXiv:2511.22325v1 Announce Type: new  Abstract: Urban economic vitality is a crucial indicator of a city&#x27;s long-term growth potential, comprising key metrics…</td><td>2025-12-01T05:00:00Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Models</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z • Source: <a href="https://huggingface.co/api/models" target="_blank" rel="noopener">https://huggingface.co/api/models</a> • Hash: <code>edb3d86947c5f8d876d9c4481cb4419a0d2e7876af7b8f691870930c02d571fc</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Model</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/Falconsai/nsfw_image_detection" target="_blank" rel="noopener">Falconsai/nsfw_image_detection</a></td><td>122866637</td><td>847</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" target="_blank" rel="noopener">sentence-transformers/all-MiniLM-L6-v2</a></td><td>118061338</td><td>4004</td></tr>
      <tr><td><a href="https://huggingface.co/dima806/fairface_age_image_detection" target="_blank" rel="noopener">dima806/fairface_age_image_detection</a></td><td>81641974</td><td>44</td></tr>
      <tr><td><a href="https://huggingface.co/google/electra-base-discriminator" target="_blank" rel="noopener">google/electra-base-discriminator</a></td><td>58549625</td><td>66</td></tr>
      <tr><td><a href="https://huggingface.co/google-bert/bert-base-uncased" target="_blank" rel="noopener">google-bert/bert-base-uncased</a></td><td>53275807</td><td>2441</td></tr>
      <tr><td><a href="https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k" target="_blank" rel="noopener">timm/mobilenetv3_small_100.lamb_in1k</a></td><td>43762365</td><td>39</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-large" target="_blank" rel="noopener">FacebookAI/roberta-large</a></td><td>20426777</td><td>250</td></tr>
      <tr><td><a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" target="_blank" rel="noopener">sentence-transformers/all-mpnet-base-v2</a></td><td>17830892</td><td>1170</td></tr>
      <tr><td><a href="https://huggingface.co/openai/clip-vit-base-patch32" target="_blank" rel="noopener">openai/clip-vit-base-patch32</a></td><td>17638896</td><td>782</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/segmentation-3.0" target="_blank" rel="noopener">pyannote/segmentation-3.0</a></td><td>17234148</td><td>626</td></tr>
      <tr><td><a href="https://huggingface.co/tech4humans/yolov8s-signature-detector" target="_blank" rel="noopener">tech4humans/yolov8s-signature-detector</a></td><td>16874538</td><td>48</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM" target="_blank" rel="noopener">pyannote/wespeaker-voxceleb-resnet34-LM</a></td><td>14933122</td><td>80</td></tr>
      <tr><td><a href="https://huggingface.co/Bingsu/adetailer" target="_blank" rel="noopener">Bingsu/adetailer</a></td><td>14489181</td><td>620</td></tr>
      <tr><td><a href="https://huggingface.co/FacebookAI/roberta-base" target="_blank" rel="noopener">FacebookAI/roberta-base</a></td><td>14321545</td><td>529</td></tr>
      <tr><td><a href="https://huggingface.co/pyannote/speaker-diarization-3.1" target="_blank" rel="noopener">pyannote/speaker-diarization-3.1</a></td><td>14186095</td><td>1228</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>GitHub Trending Repositories</h2>
  <p class="metadata">Fetched at 2025-12-01T05:43:03Z • Source: <a href="https://api.github.com/search/repositories" target="_blank" rel="noopener">https://api.github.com/search/repositories</a> • Hash: <code>0249036fe13f90378ebb86fc0e4d92ce0f324c52a686f8389895f9e3b1e8d680</code></p>
  <table>
    <thead>
      <tr><th>Repository</th><th>Stars</th><th>Description</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://github.com/Shiva108/ai-llm-red-team-handbook" target="_blank" rel="noopener">Shiva108/ai-llm-red-team-handbook</a></td><td>95</td><td>AI / LLM Red Team Field Manual &amp; Consultant’s Handbook</td></tr>
      <tr><td><a href="https://github.com/UW-Madison-Lee-Lab/LLM-judge-reporting" target="_blank" rel="noopener">UW-Madison-Lee-Lab/LLM-judge-reporting</a></td><td>36</td><td>A simple plug-in framework that corrects bias and computes confidence intervals in reporting LLM-as-a-judge evaluation, and an adaptive algorithm that efficien…</td></tr>
      <tr><td><a href="https://github.com/Koko-boya/Comfyui-Z-Image-Utilities" target="_blank" rel="noopener">Koko-boya/Comfyui-Z-Image-Utilities</a></td><td>32</td><td>ComfyUI utility nodes for Z-Image model. Features LLM-powered prompt enhancement using the official Z-Image system prompt.</td></tr>
      <tr><td><a href="https://github.com/ZON-Format/zon-TS" target="_blank" rel="noopener">ZON-Format/zon-TS</a></td><td>31</td><td>ZON → 35-70% cheaper LLM prompts than JSON/TOON. Zero overhead.</td></tr>
      <tr><td><a href="https://github.com/NullStarrySky/Pulsar" target="_blank" rel="noopener">NullStarrySky/Pulsar</a></td><td>22</td><td>现代化，模块化，强大的LLM对话前端</td></tr>
      <tr><td><a href="https://github.com/VitoKon/Semantic-Keyword-Builder" target="_blank" rel="noopener">VitoKon/Semantic-Keyword-Builder</a></td><td>19</td><td>This app uses a large language model to generate a semantic keyword Universe (EAV-based) for SEO/content strategy. It returns a structured keyword list and let…</td></tr>
      <tr><td><a href="https://github.com/maruhan12-max/AI-Compliance-Failure-Patterns" target="_blank" rel="noopener">maruhan12-max/AI-Compliance-Failure-Patterns</a></td><td>18</td><td>지시 불이행(Instruction Non-Compliance) 현상을 유발하는 프롬프트 패턴 11가지(A-K) - ChatGPT, Gemini 등 주요 LLM 모델들의 취약성 및 정책 충돌 대응 방식을 비교 분석 프로젝트</td></tr>
      <tr><td><a href="https://github.com/WhiskeyCoder/HomeLab-Log-Analyzer" target="_blank" rel="noopener">WhiskeyCoder/HomeLab-Log-Analyzer</a></td><td>16</td><td>A fully-local, fully-automated system that turns your chaotic Docker logs into clean, structured, actionable intelligence, every night, powered by your own loc…</td></tr>
      <tr><td><a href="https://github.com/klei30/tinker-ui" target="_blank" rel="noopener">klei30/tinker-ui</a></td><td>15</td><td>A user-friendly interface built on top of Thinking Machines Tinker API that lets you fine-tune LLMs, chat with your trained model, and deploy to Hugging Face.</td></tr>
      <tr><td><a href="https://github.com/Adil-Ijaz7/Mobius-LLM-Fine-tuning-Engine" target="_blank" rel="noopener">Adil-Ijaz7/Mobius-LLM-Fine-tuning-Engine</a></td><td>13</td><td>LLM Fine-tuning Engine with GUI and ML Core</td></tr>
      <tr><td><a href="https://github.com/eastsea17/GraphRAG_with_Ollama" target="_blank" rel="noopener">eastsea17/GraphRAG_with_Ollama</a></td><td>11</td><td>A local-LLM based Graph RAG agent using FalkorDB</td></tr>
      <tr><td><a href="https://github.com/jart/zipalign" target="_blank" rel="noopener">jart/zipalign</a></td><td>11</td><td>PKZip for LLMs</td></tr>
      <tr><td><a href="https://github.com/ktock/llmlet" target="_blank" rel="noopener">ktock/llmlet</a></td><td>11</td><td>P2P distributed LLM inference on browsers</td></tr>
      <tr><td><a href="https://github.com/hengzzzhou/FigForge" target="_blank" rel="noopener">hengzzzhou/FigForge</a></td><td>10</td><td>AI-powered scientific figure generator using LLM analysis and nano banana for publication-quality visualizations</td></tr>
      <tr><td><a href="https://github.com/nku-zhichengzhang/Awesome-emotion_llm_and_mllm" target="_blank" rel="noopener">nku-zhichengzhang/Awesome-emotion_llm_and_mllm</a></td><td>8</td><td>Awesome papers for affective computing with llm and mllm</td></tr>
      <tr><td><a href="https://github.com/Shepherd010/MDtranslator" target="_blank" rel="noopener">Shepherd010/MDtranslator</a></td><td>7</td><td>下一代 LLM 驱动的所见即所得 Markdown 翻译工作台</td></tr>
      <tr><td><a href="https://github.com/ibrahim-ansari-code/LLM-Council-IDE" target="_blank" rel="noopener">ibrahim-ansari-code/LLM-Council-IDE</a></td><td>7</td><td>Drawing inspiration from Andrej Karpathy&#x27;s LLM Council, this is an implementation for coding. LLMs evaluate each other and generate the best result rather than…</td></tr>
      <tr><td><a href="https://github.com/yaolinli/MLLM-Token-Compression" target="_blank" rel="noopener">yaolinli/MLLM-Token-Compression</a></td><td>7</td><td>Towards Efficient Multimodal Large Language Models: A Survey on Token Compression</td></tr>
      <tr><td><a href="https://github.com/BatsResearch/cross-difficulty" target="_blank" rel="noopener">BatsResearch/cross-difficulty</a></td><td>6</td><td>Analysis of LLM generalization across difficulty levels using Item Response Theory</td></tr>
      <tr><td><a href="https://github.com/Blockly-Anice/AI-image-recognition-chatbot-LLM-model" target="_blank" rel="noopener">Blockly-Anice/AI-image-recognition-chatbot-LLM-model</a></td><td>6</td><td>This is an AI-Gemini Chatbot LLM And Large Image Model Application. You can use this project run into local and ask you images like your talking with in realti…</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Papers with Code</h2>
  <p class="metadata">Fetched at 2025-10-17T00:47:37Z • Source: <a href="https://paperswithcode.com/api/v1/papers/" target="_blank" rel="noopener">https://paperswithcode.com/api/v1/papers/</a> • Hash: <code>d4a343f7408e936b9b783882d60713e7711a2e2104b924d1a9726c2b1660e60c</code></p>
  <p class="warning">Expecting value: line 1 column 1 (char 0)</p>
  <p class="empty">No data available.</p>
</section><section>
  <h2>Hacker News Highlights</h2>
  <p class="metadata">Fetched at 2025-12-01T05:43:03Z • Source: <a href="https://hacker-news.firebaseio.com/" target="_blank" rel="noopener">https://hacker-news.firebaseio.com/</a> • Hash: <code>12c602e8b1f6792b20a4e4fe1d76a8c57f20bc312e16e3a0ddda47528b1ee2a9</code></p>
  <table>
    <thead>
      <tr><th>Story</th><th>Score</th><th>Published</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://gpt3experiments.substack.com/p/dont-push-ai-down-our-throats" target="_blank" rel="noopener">Don&#x27;t push AI down our throats</a></td><td>381</td><td>2025-11-30T18:17:13Z</td></tr>
      <tr><td><a href="https://thinkinggamefilm.com" target="_blank" rel="noopener">The Thinking Game Film – Google DeepMind documentary</a></td><td>167</td><td>2025-11-30T16:07:11Z</td></tr>
      <tr><td><a href="https://news.ycombinator.com/item?id=46095873" target="_blank" rel="noopener">Tell HN: It&#x27;s now impossible to disable all AI features in Firefox 145 (latest)</a></td><td>51</td><td>2025-11-30T11:48:42Z</td></tr>
      <tr><td><a href="https://www.macstories.net/stories/ipad-pro-m5-neural-benchmarks-mlx/" target="_blank" rel="noopener">I Tested the M5 iPad Pro&#x27;s Neural-Accelerated AI, and the Hype Is Real</a></td><td>21</td><td>2025-12-01T03:09:35Z</td></tr>
      <tr><td><a href="https://www.planetearthandbeyond.co/p/did-nvidia-just-prove-there-is-no" target="_blank" rel="noopener">Did Nvidia Just Prove There Is No AI Bubble</a></td><td>18</td><td>2025-11-30T21:55:15Z</td></tr>
      <tr><td><a href="https://trajancolumn.com" target="_blank" rel="noopener">AI rendering of Roman war scenes from Trajan&#x27;s Column</a></td><td>15</td><td>2025-11-30T19:58:48Z</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Latest CVEs</h2>
  <p class="metadata">Fetched at 2025-12-01T05:43:03Z • Source: <a href="https://cve.circl.lu/api/last" target="_blank" rel="noopener">https://cve.circl.lu/api/last</a> • Hash: <code>65c6462a484bde2018771227dda2b5cd2057adb276cdc4e00a70a8b5b87e2bac</code></p>
  <table>
    <thead>
      <tr><th>CVE</th><th>CVSS</th><th>Summary</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-191156" target="_blank" rel="noopener">MAL-2025-191156</a></td><td>0.0</td><td>Malicious code in zuper-sdk (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-191155" target="_blank" rel="noopener">MAL-2025-191155</a></td><td>0.0</td><td>Malicious code in wenk (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-191438" target="_blank" rel="noopener">MAL-2025-191438</a></td><td>0.0</td><td>Malicious code in typeface-antonio-complete (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-191437" target="_blank" rel="noopener">MAL-2025-191437</a></td><td>0.0</td><td>Malicious code in ts-relay-cursor-paging (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-191436" target="_blank" rel="noopener">MAL-2025-191436</a></td><td>0.0</td><td>Malicious code in toonfetch (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-191435" target="_blank" rel="noopener">MAL-2025-191435</a></td><td>0.0</td><td>Malicious code in tiptap-shadcn-vue (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-191434" target="_blank" rel="noopener">MAL-2025-191434</a></td><td>0.0</td><td>Malicious code in test23112222-api (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-191432" target="_blank" rel="noopener">MAL-2025-191432</a></td><td>0.0</td><td>Malicious code in tavily-module (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-191439" target="_blank" rel="noopener">MAL-2025-191439</a></td><td>0.0</td><td>Malicious code in unadapter (npm)</td></tr>
      <tr><td><a href="https://www.cve.org/CVERecord?id=MAL-2025-191440" target="_blank" rel="noopener">MAL-2025-191440</a></td><td>0.0</td><td>Malicious code in unemail (npm)</td></tr>
    </tbody>
  </table>
</section><section>
  <h2>Hugging Face Trending Datasets</h2>
  <p class="metadata">Fetched at 2025-10-16T23:53:44Z • Source: <a href="https://huggingface.co/api/datasets" target="_blank" rel="noopener">https://huggingface.co/api/datasets</a> • Hash: <code>4b4cc33871c4b3cd497c500155aa79f37885aa24df2d895e1d18c0c80ab6ae9c</code></p>
  <p class="warning">Illegal header value b&#x27;Bearer &#x27;</p>
  <table>
    <thead>
      <tr><th>Dataset</th><th>Downloads</th><th>Likes</th></tr>
    </thead>
    <tbody>
      <tr><td><a href="https://huggingface.co/datasets/nebius/SWE-rebench" target="_blank" rel="noopener">nebius/SWE-rebench</a></td><td>3717252</td><td>35</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/SWE-Gym/SWE-Gym" target="_blank" rel="noopener">SWE-Gym/SWE-Gym</a></td><td>2041687</td><td>20</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/huggingface/documentation-images" target="_blank" rel="noopener">huggingface/documentation-images</a></td><td>2014781</td><td>86</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/chcorbi/helvipad" target="_blank" rel="noopener">chcorbi/helvipad</a></td><td>1478443</td><td>10</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/AquaV/genshin-voices-separated" target="_blank" rel="noopener">AquaV/genshin-voices-separated</a></td><td>1461805</td><td>8</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/banned-historical-archives/banned-historical-archives" target="_blank" rel="noopener">banned-historical-archives/banned-historical-archives</a></td><td>1411450</td><td>5</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim" target="_blank" rel="noopener">nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim</a></td><td>1339503</td><td>155</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/princeton-nlp/SWE-bench_Verified" target="_blank" rel="noopener">princeton-nlp/SWE-bench_Verified</a></td><td>1282494</td><td>218</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/lavita/medical-qa-shared-task-v1-toy" target="_blank" rel="noopener">lavita/medical-qa-shared-task-v1-toy</a></td><td>878541</td><td>21</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/Salesforce/wikitext" target="_blank" rel="noopener">Salesforce/wikitext</a></td><td>867174</td><td>505</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/language_table_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/language_table_lerobot</a></td><td>786287</td><td>0</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/IPEC-COMMUNITY/droid_lerobot" target="_blank" rel="noopener">IPEC-COMMUNITY/droid_lerobot</a></td><td>737114</td><td>6</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/hf-doc-build/doc-build" target="_blank" rel="noopener">hf-doc-build/doc-build</a></td><td>671848</td><td>12</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/applied-ai-018/pretraining_v1-omega_books" target="_blank" rel="noopener">applied-ai-018/pretraining_v1-omega_books</a></td><td>614296</td><td>2</td></tr>
      <tr><td><a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu" target="_blank" rel="noopener">HuggingFaceFW/fineweb-edu</a></td><td>597646</td><td>775</td></tr>
    </tbody>
  </table>
</section>
  </main>
  <footer><p>Datasets updated as part of the DeepTech Daily automation run.</p><p>Last refreshed at 2025-12-01T05:43:03Z.</p><ul><li><a href="../deeptech-daily/data/gpu_prices.json">gpu_prices.json</a></li><li><a href="../deeptech-daily/data/arxiv.yaml">arxiv.yaml</a></li><li><a href="../deeptech-daily/data/hf_trending.yaml">hf_trending.yaml</a></li><li><a href="../deeptech-daily/data/github_trending.yaml">github_trending.yaml</a></li><li><a href="../deeptech-daily/data/pwc_llm.yaml">pwc_llm.yaml</a></li><li><a href="../deeptech-daily/data/hn_ai.yaml">hn_ai.yaml</a></li><li><a href="../deeptech-daily/data/cves.yaml">cves.yaml</a></li><li><a href="../deeptech-daily/data/hf_datasets.yaml">hf_datasets.yaml</a></li></ul></footer>
</body>
</html>
